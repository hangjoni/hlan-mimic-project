{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hungryfoolish/anaconda3/envs/hlan/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "# import constants\n",
    "from constants import *\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import load_data_multilabel_pre_split , create_dataloaders, initialize_model, create_subset_dataloader, create_vocabulary_label_pre_split, create_vocabulary\n",
    "from HAN_model import HierarchicalAttentionNetwork\n",
    "\n",
    "from metrics import *\n",
    "from train import train\n",
    "\n",
    "import captum\n",
    "from captum.attr import LayerIntegratedGradients, TokenReferenceBase, visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n",
      "load_data.started...\n",
      "load_data_multilabel_new.data_path: ../datasets/data/train_50_eamc.csv\n",
      "load_data.ended...\n",
      "load_data.started...\n",
      "load_data_multilabel_new.data_path: ../datasets/data/dev_50_eamc.csv\n",
      "load_data.ended...\n",
      "shuffled training data\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, vocab_size = create_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tiny_loader = create_subset_dataloader(valid_dataloader, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HierarchicalAttentionNetwork(vocab_size=vocab_size, embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, num_sentences=NUM_SENTENCES, sentence_length=SENTENCE_LENGTH, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"../checkpoints/20231128_1247_100epochs_yPaLn/best_valid_loss.pt\", map_location='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def forward_with_sigmoid(input):\n",
    "    return torch.sigmoid(model(input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    }
   ],
   "source": [
    "vocabulary_word2index, vocabulary_index2word = create_vocabulary(WORD2VEC_MODEL_PATH,name_scope=DATASET + \"-HAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_word2index_label,vocabulary_index2word_label = create_vocabulary_label_pre_split(training_data_path=TRAINING_DATA_PATH, validation_data_path=VALIDATION_DATA_PATH, testing_data_path=TESTING_DATA_PATH, name_scope=DATASET + \"-HAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_ID = 0\n",
    "token_reference = TokenReferenceBase(reference_token_idx=PAD_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lig = LayerIntegratedGradients(model, model.embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data_records_ig = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(tiny_loader))\n",
    "pred = forward_with_sigmoid(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6.9934e-01, 1.1955e-02, 8.1924e-02, 6.1842e-03, 3.3330e-01, 6.4586e-02,\n",
       "         1.9102e-02, 2.0049e-02, 3.1443e-01, 7.5767e-01, 4.9988e-01, 8.2690e-02,\n",
       "         4.2240e-02, 6.7354e-04, 2.8976e-02, 5.4142e-02, 1.5240e-01, 2.6216e-01,\n",
       "         1.4898e-02, 6.3594e-03, 1.1615e-01, 1.7024e-03, 5.8901e-05, 3.7454e-02,\n",
       "         2.1619e-01, 1.1237e-04, 9.1838e-03, 1.8380e-02, 1.5117e-03, 8.1204e-03,\n",
       "         1.8971e-02, 5.1045e-03, 1.3901e-02, 5.1605e-02, 9.4627e-03, 4.3310e-02,\n",
       "         5.1580e-03, 3.2039e-02, 8.2546e-02, 1.7999e-03, 3.4053e-01, 1.2028e-03,\n",
       "         4.5430e-03, 2.8430e-03, 2.4618e-04, 7.3593e-02, 2.6221e-03, 1.6576e-02,\n",
       "         1.6066e-03, 6.0232e-04]], grad_fn=<SigmoidBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.argmax(pred, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_indices = token_reference.generate_reference(SEQUENCE_LENGTH, device='cpu').unsqueeze(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2500])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_indices.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 2500])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute attributions and approximation delta using layer integrated gradients\n",
    "attributions_ig, delta = lig.attribute(x, reference_indices, target = torch.argmax(pred, dim=1).item(), return_convergence_delta=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "attributions = attributions_ig.sum(dim=2).squeeze(0)\n",
    "attributions = attributions / torch.norm(attributions)\n",
    "attributions = attributions.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'96.6'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vis_data_records_ig = []\n",
    "pred_ind = torch.argmax(pred, dim=1)\n",
    "pred_label = vocabulary_index2word_label[pred_ind.item()]\n",
    "pred_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:,pred_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = [vocabulary_index2word[i.item()] for i in x[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([9])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.76'"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f\"{pred[:,pred_ind.item()].item():.2f}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "vis_data_records_ig.append(visualization.VisualizationDataRecord(\n",
    "    attributions,\n",
    "    pred[:,pred_ind.item()].item(),\n",
    "    pred_label,\n",
    "    pred_label,\n",
    "    pred_label,\n",
    "    attributions.sum(),\n",
    "    text,\n",
    "    delta))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported format string passed to Tensor.__format__",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/hungryfoolish/Documents/OMSCS/BD4H/hlan-mimic-project/HLAN_pytorch/visualization_playground.ipynb Cell 27\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hungryfoolish/Documents/OMSCS/BD4H/hlan-mimic-project/HLAN_pytorch/visualization_playground.ipynb#X35sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m _ \u001b[39m=\u001b[39m visualization\u001b[39m.\u001b[39;49mvisualize_text(vis_data_records_ig)\n",
      "File \u001b[0;32m~/anaconda3/envs/hlan/lib/python3.11/site-packages/captum/attr/_utils/visualization.py:863\u001b[0m, in \u001b[0;36mvisualize_text\u001b[0;34m(datarecords, legend)\u001b[0m\n\u001b[1;32m    849\u001b[0m rows \u001b[39m=\u001b[39m [\n\u001b[1;32m    850\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<tr><th>True Label</th>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    851\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<th>Predicted Label</th>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    854\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39m<th>Word Importance</th>\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    855\u001b[0m ]\n\u001b[1;32m    856\u001b[0m \u001b[39mfor\u001b[39;00m datarecord \u001b[39min\u001b[39;00m datarecords:\n\u001b[1;32m    857\u001b[0m     rows\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    858\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[1;32m    859\u001b[0m             [\n\u001b[1;32m    860\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m<tr>\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    861\u001b[0m                 format_classname(datarecord\u001b[39m.\u001b[39mtrue_class),\n\u001b[1;32m    862\u001b[0m                 format_classname(\n\u001b[0;32m--> 863\u001b[0m                     \u001b[39m\"\u001b[39;49m\u001b[39m{0}\u001b[39;49;00m\u001b[39m (\u001b[39;49m\u001b[39m{1:.2f}\u001b[39;49;00m\u001b[39m)\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m.\u001b[39;49mformat(\n\u001b[1;32m    864\u001b[0m                         datarecord\u001b[39m.\u001b[39;49mpred_class, datarecord\u001b[39m.\u001b[39;49mpred_prob\n\u001b[1;32m    865\u001b[0m                     )\n\u001b[1;32m    866\u001b[0m                 ),\n\u001b[1;32m    867\u001b[0m                 format_classname(datarecord\u001b[39m.\u001b[39mattr_class),\n\u001b[1;32m    868\u001b[0m                 format_classname(\u001b[39m\"\u001b[39m\u001b[39m{0:.2f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(datarecord\u001b[39m.\u001b[39mattr_score)),\n\u001b[1;32m    869\u001b[0m                 format_word_importances(\n\u001b[1;32m    870\u001b[0m                     datarecord\u001b[39m.\u001b[39mraw_input_ids, datarecord\u001b[39m.\u001b[39mword_attributions\n\u001b[1;32m    871\u001b[0m                 ),\n\u001b[1;32m    872\u001b[0m                 \u001b[39m\"\u001b[39m\u001b[39m<tr>\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[1;32m    873\u001b[0m             ]\n\u001b[1;32m    874\u001b[0m         )\n\u001b[1;32m    875\u001b[0m     )\n\u001b[1;32m    877\u001b[0m \u001b[39mif\u001b[39;00m legend:\n\u001b[1;32m    878\u001b[0m     dom\u001b[39m.\u001b[39mappend(\n\u001b[1;32m    879\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m<div style=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mborder-top: 1px solid; margin-top: 5px; \u001b[39m\u001b[39m\\\u001b[39;00m\n\u001b[1;32m    880\u001b[0m \u001b[39m        padding-top: 5px; display: inline-block\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m>\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    881\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/hlan/lib/python3.11/site-packages/torch/_tensor.py:934\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdim() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mis_meta \u001b[39mand\u001b[39;00m \u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39mis\u001b[39;00m Tensor:\n\u001b[1;32m    933\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mitem()\u001b[39m.\u001b[39m\u001b[39m__format__\u001b[39m(format_spec)\n\u001b[0;32m--> 934\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mobject\u001b[39;49m\u001b[39m.\u001b[39;49m\u001b[39m__format__\u001b[39;49m(\u001b[39mself\u001b[39;49m, format_spec)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to Tensor.__format__"
     ]
    }
   ],
   "source": [
    "_ = visualization.visualize_text(vis_data_records_ig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "hlan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
