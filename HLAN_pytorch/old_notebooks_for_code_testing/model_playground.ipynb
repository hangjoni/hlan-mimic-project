{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from gensim.models import Word2Vec\n",
    "from constants import *\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import create_vocabulary_label_pre_split, create_vocabulary\n",
    "from utils import load_data_multilabel_pre_split , create_dataloaders\n",
    "from HAN_model import HierarchicalAttentionNetwork"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/datasets/data/train_50_eamc.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "workspaceFolder = \"/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master\"\n",
    "word2vec_model_path = f\"{workspaceFolder}/embeddings/processed_full.w2v\"\n",
    "\n",
    "word2vec_label_path_200 = f\"{workspaceFolder}/embeddings/train_full-code-emb-mimic3-tr-200.model\"\n",
    "word2vec_label_path_400 = f\"{workspaceFolder}/embeddings/train_full-code-emb-mimic3-tr-400.model\"\n",
    "\n",
    "training_data_path = f\"{workspaceFolder}/datasets/data/train_50_eamc.csv\"\n",
    "validation_data_path = f\"{workspaceFolder}/datasets/data/dev_50_eamc.csv\"\n",
    "testing_data_path = f\"{workspaceFolder}/datasets/data/test_50_eamc.csv\"\n",
    "dataset = \"mimic3-ds-50\"\n",
    "num_classes = 50\n",
    "sequence_length = 2500\n",
    "batch_size = 32\n",
    "embed_size=100\n",
    "hidden_size=100\n",
    "num_sentences=100\n",
    "sentence_length=sequence_length // num_sentences\n",
    "training_data_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_word2index_label,vocabulary_index2word_label = create_vocabulary_label_pre_split(training_data_path=training_data_path, validation_data_path=validation_data_path, testing_data_path=testing_data_path, name_scope=dataset + \"-HAN\") # keep a distinct name scope for each model and each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    }
   ],
   "source": [
    "vocabulary_word2index, vocabulary_index2word = create_vocabulary(word2vec_model_path,name_scope=dataset + \"-HAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150854"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_word2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vocabulary_word2index_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load_data.started...\n",
      "load_data_multilabel_new.data_path: /Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/datasets/data/train_50_eamc.csv\n",
      "load_data.ended...\n"
     ]
    }
   ],
   "source": [
    "X, Y = load_data_multilabel_pre_split(vocabulary_word2index, vocabulary_word2index_label, data_path=training_data_path, keep_label_percent=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8066, 8066)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X), len(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7567"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(x) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step through data loading code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this is the maximum sequence length, quite higher than 2500. So currently those text are truncated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 50)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(Y[0]), len(Y[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_or_truncate_sequence(sequence, maxlen):\n",
    "    if len(sequence) > maxlen:\n",
    "        sequence = sequence[:maxlen]\n",
    "    elif len(sequence) < maxlen:\n",
    "        sequence += [0] * (maxlen - len(sequence))\n",
    "    return sequence\n",
    "\n",
    "X_padded = [pad_or_truncate_sequence(x, sequence_length) for x in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 2500)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([len(x) for x in X_padded]), min([len(x) for x in X_padded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8066, 2500])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(X_padded).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert your data to PyTorch tensors\n",
    "# split X into sentences\n",
    "X_tensor = torch.tensor(X_padded)\n",
    "Y_tensor = torch.tensor(Y)\n",
    "\n",
    "# Create a TensorDataset from your tensors\n",
    "dataset = TensorDataset(X_tensor, Y_tensor)\n",
    "\n",
    "# Create a DataLoader from your dataset\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2500]) torch.Size([32, 50])\n"
     ]
    }
   ],
   "source": [
    "# Now you can iterate over the DataLoader to get your batches\n",
    "for X_batch, Y_batch in dataloader:\n",
    "    # Process the batch\n",
    "    print(X_batch.shape, Y_batch.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test dataloading code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n",
      "load_data.started...\n",
      "load_data_multilabel_new.data_path: /Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/datasets/data/train_50_eamc.csv\n",
      "load_data.ended...\n"
     ]
    }
   ],
   "source": [
    "#from utils import create_train_dataloader\n",
    "\n",
    "dataloader = create_train_dataloader()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 2500]) torch.Size([32, 50])\n"
     ]
    }
   ],
   "source": [
    "for x, y in dataloader:\n",
    "    print(x.shape, y.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step through the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "_embeddings = nn.Embedding(vocab_size, embed_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_documents = _embeddings(X_batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2500, 100])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "_word_gru = nn.GRU(embed_size, hidden_size, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words, _ = _word_gru(embedded_documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2500, 200])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25, 200])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words = output_words.view(batch_size, num_sentences, sentence_length, 2 * hidden_size)\n",
    "output_words.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, input_size, output_size):\n",
    "        super(Attention, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.output_size = output_size\n",
    "        self.linear = nn.Linear(input_size, output_size)\n",
    "        self.context_vector = nn.Parameter(torch.randn((output_size)))\n",
    "        \n",
    "    def forward(self, input):\n",
    "        hidden_representation = torch.tanh(self.linear(input))\n",
    "        attention_logits = torch.sum(hidden_representation * self.context_vector, dim=-1)\n",
    "        \n",
    "        # for numerical stability, subtract the max of the attention logits\n",
    "        attention_logits_max, _ = torch.max(attention_logits, dim=-1, keepdim=True) \n",
    "        attention = F.softmax(attention_logits - attention_logits_max, dim=-1)\n",
    "\n",
    "        output = torch.sum(input * attention.unsqueeze(-1), dim=-2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### step through attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25, 200])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear = nn.Linear(2 * hidden_size, 2 * hidden_size)\n",
    "hidden_representation = torch.tanh(linear(output_words))\n",
    "hidden_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_vector = nn.Parameter(torch.randn((2 * hidden_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_logits = torch.sum(hidden_representation * context_vector, dim=-1)\n",
    "attention_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 1])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_logits_max, _ = torch.max(attention_logits, dim=-1, keepdim=True)\n",
    "attention_logits_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = F.softmax(attention_logits - attention_logits_max, dim=-1)\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25, 1])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 200])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_representation = torch.sum(output_words * attention.unsqueeze(-1), dim=-2)\n",
    "sentence_representation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resume using attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "_word_attention = Attention(hidden_size * 2, hidden_size * 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words_attn = _word_attention(output_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 200])"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words_attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_gru = nn.GRU(2*hidden_size, 2*hidden_size, bidirectional=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 400])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences, _ = sentence_gru(output_words_attn)\n",
    "output_sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step through sentence attention code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4*hidden_size\n",
    "output_size = 2*hidden_size\n",
    "linear = nn.Linear(input_size, output_size)\n",
    "context_vector = nn.Parameter(torch.randn((output_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 400])"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = output_sentences\n",
    "input.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 200])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_representation = torch.tanh(linear(input))\n",
    "hidden_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_logits = torch.sum(hidden_representation * context_vector, dim=-1)\n",
    "attention_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100])"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_logits_max, _ = torch.max(attention_logits, dim=-1, keepdim=True) \n",
    "attention = F.softmax(attention_logits - attention_logits_max, dim=-1)\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 1])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.unsqueeze(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 400])"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = input * attention.unsqueeze(-1)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 400])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.sum(input * attention.unsqueeze(-1), dim=-2)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resume with sentence attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_attention = Attention(4*hidden_size, 2*hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 400])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences_attn = sentence_attention(output_sentences)\n",
    "output_sentences_attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fc = nn.Linear(4*hidden_size, num_classes)\n",
    "output = fc(output_sentences_attn)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HierarchicalAttentionNetwork(batch_size=batch_size, vocab_size=vocab_size, embed_size=embed_size, hidden_size=hidden_size, num_sentences=num_sentences, sentence_length=sentence_length, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings.weight torch.Size([150854, 100])\n",
      "word_gru.weight_ih_l0 torch.Size([300, 100])\n",
      "word_gru.weight_hh_l0 torch.Size([300, 100])\n",
      "word_gru.bias_ih_l0 torch.Size([300])\n",
      "word_gru.bias_hh_l0 torch.Size([300])\n",
      "word_gru.weight_ih_l0_reverse torch.Size([300, 100])\n",
      "word_gru.weight_hh_l0_reverse torch.Size([300, 100])\n",
      "word_gru.bias_ih_l0_reverse torch.Size([300])\n",
      "word_gru.bias_hh_l0_reverse torch.Size([300])\n",
      "sentence_gru.weight_ih_l0 torch.Size([600, 200])\n",
      "sentence_gru.weight_hh_l0 torch.Size([600, 200])\n",
      "sentence_gru.bias_ih_l0 torch.Size([600])\n",
      "sentence_gru.bias_hh_l0 torch.Size([600])\n",
      "sentence_gru.weight_ih_l0_reverse torch.Size([600, 200])\n",
      "sentence_gru.weight_hh_l0_reverse torch.Size([600, 200])\n",
      "sentence_gru.bias_ih_l0_reverse torch.Size([600])\n",
      "sentence_gru.bias_hh_l0_reverse torch.Size([600])\n",
      "word_attention.context_vector torch.Size([200])\n",
      "word_attention.linear.weight torch.Size([200, 200])\n",
      "word_attention.linear.bias torch.Size([200])\n",
      "sentence_attention.context_vector torch.Size([200])\n",
      "sentence_attention.linear.weight torch.Size([200, 400])\n",
      "sentence_attention.linear.bias torch.Size([200])\n",
      "fc.weight torch.Size([50, 400])\n",
      "fc.bias torch.Size([50])\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name, param.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embed_size, model.hidden_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step through model iteration 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2500, 100])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_embeddings = nn.Embedding(vocab_size, embed_size)\n",
    "embedded_documents = _embeddings(x)\n",
    "embedded_documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_gru = nn.GRU(embed_size, hidden_size, bidirectional=False) # paper model only has 1 set of parameters, don't have a separate parameters set for reverse direction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2500, 100])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words_left2right, _ = word_gru(embedded_documents)\n",
    "output_words_left2right.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2500, 100])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words_right2left, _ = word_gru(embedded_documents)\n",
    "output_words_right2left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25, 100])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reverse the order of right2left\n",
    "output_words_right2left_reshaped = output_words_right2left.view(-1, num_sentences, sentence_length, embed_size)\n",
    "output_words_right2left_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### understand .flip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  0,   1,   2,   3],\n",
       "         [  4,   5,   6,   7]],\n",
       "\n",
       "        [[  8,   9,  10,  11],\n",
       "         [ 12,  13,  14,  15]],\n",
       "\n",
       "        [[100, 101, 102, 103],\n",
       "         [104, 105, 106, 107]]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([\n",
    "        [[0, 1, 2, 3], [4, 5, 6, 7]],\n",
    "        [[8, 9, 10, 11], [12, 13, 14, 15]],\n",
    "        [[100, 101, 102, 103], [104, 105, 106, 107]]\n",
    "        ])\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 2, 4])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[100, 101, 102, 103],\n",
       "         [104, 105, 106, 107]],\n",
       "\n",
       "        [[  8,   9,  10,  11],\n",
       "         [ 12,  13,  14,  15]],\n",
       "\n",
       "        [[  0,   1,   2,   3],\n",
       "         [  4,   5,   6,   7]]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.flip(dims=[0])\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  4,   5,   6,   7],\n",
       "         [  0,   1,   2,   3]],\n",
       "\n",
       "        [[ 12,  13,  14,  15],\n",
       "         [  8,   9,  10,  11]],\n",
       "\n",
       "        [[104, 105, 106, 107],\n",
       "         [100, 101, 102, 103]]])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a.flip(dims=[1])\n",
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### resume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25, 100])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words_right2left_reshaped_reversed = output_words_right2left_reshaped.flip(dims=[2])\n",
    "output_words_right2left_reshaped_reversed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2500, 100])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words_right2left_reversed = output_words_right2left_reshaped_reversed.view(batch_size, num_sentences * sentence_length, embed_size)\n",
    "output_words_right2left_reversed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2500, 200])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words = torch.cat((output_words_left2right, output_words_right2left_reversed), dim=-1)\n",
    "output_words.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Word level attention step through, with per label attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = output_size = 2 * hidden_size\n",
    "linear = nn.Linear(input_size, output_size)\n",
    "context_vector = nn.Parameter(torch.randn((num_classes, output_size)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 200])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 50, 200])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector.unsqueeze(0).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 200, 50])"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector.unsqueeze(0).unsqueeze(0).transpose(-1, -2).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 2500, 200])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = output_words\n",
    "hidden_representation = torch.tanh(linear(input_tensor))\n",
    "hidden_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25, 200])"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# split both to word and sentence level\n",
    "hidden_representation_reshaped = hidden_representation.view(batch_size, num_sentences, sentence_length, output_size)\n",
    "hidden_representation_reshaped.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "trying dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100, 25, 200]) torch.Size([1, 1, 200, 50])\n"
     ]
    }
   ],
   "source": [
    "a = hidden_representation_reshaped\n",
    "b = context_vector.unsqueeze(0).unsqueeze(0).transpose(-1, -2)\n",
    "print(a.shape, b.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25, 50])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = torch.matmul(a, b)\n",
    "c.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "good, now use it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 100, 25, 200]) torch.Size([1, 1, 200, 50])\n"
     ]
    }
   ],
   "source": [
    "context_vector_expanded = context_vector.unsqueeze(0).unsqueeze(0).transpose(-1, -2)\n",
    "print(hidden_representation_reshaped.shape, context_vector_expanded.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25, 50])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_logits = torch.matmul(hidden_representation_reshaped, context_vector_expanded)\n",
    "attention_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 1, 50])"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_logits_max, _ = torch.max(attention_logits, dim=2, keepdim=True)\n",
    "attention_logits_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25, 50])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = F.softmax(attention_logits - attention_logits_max, dim=-1)\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25, 50, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_reshaped = attention.unsqueeze(-1)\n",
    "attention_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25, 1, 200])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor_reshaped = input_tensor.view(batch_size, num_sentences, sentence_length, 1, output_size)\n",
    "input_tensor_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 25, 50, 200])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = attention_reshaped * input_tensor_reshaped\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 50, 200])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.sum(temp, dim=2)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = torch.sum(input_tensor * attention.unsqueeze(-1), dim=-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resume after attention word level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attention = Attention(2*hidden_size, 2*hidden_size, per_label_attention=True, num_classes=50) # need to be separate for each class depending on input parameter per_label_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 200])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_attention.context_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words_attn = word_attention(output_words)\n",
    "output_words_attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### test Attention Word Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "from HAN_model import AttentionWordLevel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_attention = AttentionWordLevel(input_size=hidden_size*2, output_size=hidden_size*2, per_label_attention=True, num_classes=50, num_sentences=100, sentence_length=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_words_attn = word_attention(output_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 50, 200])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words_attn.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### resume with HAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_gru = nn.GRU(2*hidden_size, 2*hidden_size, bidirectional=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 50, 200])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_words_attn.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5000, 200])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# reshape to 3D tensor\n",
    "output_words_attn_reshaped = output_words_attn.view(batch_size, num_sentences*num_classes, 2*hidden_size)\n",
    "output_words_attn_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5000, 200])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences_left2right, _ = sentence_gru(output_words_attn_reshaped)\n",
    "output_sentences_left2right.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 50, 200])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences_left2right_reshaped = output_sentences_left2right.view(batch_size, num_sentences, num_classes, 2*hidden_size)\n",
    "output_sentences_left2right_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 5000, 200])"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences_right2left, _ = sentence_gru(output_words_attn_reshaped)\n",
    "output_sentences_right2left.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 50, 200])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences_right2left_reshaped = output_sentences_right2left.view(batch_size, num_sentences, num_classes, 2*hidden_size)\n",
    "output_sentences_right2left_reshaped.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 50, 200])"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences_right2left_reshaped_reversed = output_sentences_right2left_reshaped.flip(dims=[1])\n",
    "output_sentences_right2left_reshaped_reversed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 50, 400])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_sentences = torch.cat((output_sentences_left2right_reshaped, output_sentences_right2left_reshaped_reversed), dim=-1)\n",
    "output_sentences.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence level attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 4 * hidden_size\n",
    "output_size = 2 * hidden_size\n",
    "linear = nn.Linear(input_size, output_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 50, 400])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor = output_sentences\n",
    "input_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 50, 200])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_representation = torch.tanh(linear(input_tensor))\n",
    "hidden_representation.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 200])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vector = nn.Parameter(torch.randn((num_classes, output_size)))\n",
    "context_vector.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 50])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_logits = torch.sum(hidden_representation * context_vector.unsqueeze(0).unsqueeze(0), dim=-1)\n",
    "attention_logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 50])"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_logits_max, _ = torch.max(attention_logits, dim=-2, keepdim=True)\n",
    "attention_logits_max.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 50])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention = F.softmax(attention_logits - attention_logits_max, dim=-1)\n",
    "attention.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 100, 50, 400])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = attention.unsqueeze(-1) * input_tensor\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 400])"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output = torch.sum(temp, dim=1)\n",
    "output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "done with sentence attention, now the last layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = nn.Parameter(torch.randn((num_classes, hidden_size*4)))\n",
    "b = nn.Parameter(torch.randn((num_classes)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50, 400])"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "W.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50, 400])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = output *  W.unsqueeze(0)\n",
    "temp.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_output = torch.sum(temp, dim=-1) + b\n",
    "final_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Backward pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/model_playground.ipynb Cell 136\u001b[0m line \u001b[0;36m3\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/model_playground.ipynb#Y252sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# train one epoch\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/model_playground.ipynb#Y252sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/model_playground.ipynb#Y252sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (x, y) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(dataloader):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/model_playground.ipynb#Y252sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m     optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/model_playground.ipynb#Y252sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m     y_hat \u001b[39m=\u001b[39m model(x)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'dataloader' is not defined"
     ]
    }
   ],
   "source": [
    "# train one epoch\n",
    "losses = []\n",
    "for i, (x, y) in enumerate(dataloader):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(x)\n",
    "    loss = criterion(y_hat, y)\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print('iter', i, 'loss', np.array(losses).mean())\n",
    "print('done 1 epoch', 'loss:', np.array(losses).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "backward pass works. However loss was going up! Loss function in original model is more complex. Need to check and compare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "prepare the values. first, embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    }
   ],
   "source": [
    "vocabulary_word2index, vocabulary_index2word = create_vocabulary(word2vec_model_path,name_scope=dataset + \"-HAN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_w2v = Word2Vec.load(word2vec_model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150853"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word_w2v.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150854"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = len(vocabulary_word2index)\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "actual vocab has an extra word for 'PAD_ID'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a tensor with random values \n",
    "bound = np.sqrt(6.0) / np.sqrt(vocab_size)\n",
    "embeddings = torch.rand((vocab_size, embed_size)) * 2 * bound - bound\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150854, 100])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(vocab_size):\n",
    "    word = vocabulary_index2word[i]\n",
    "    # word might not exists in the word2vec model!\n",
    "    if word in word_w2v.wv.key_to_index:\n",
    "        embeddings[i] = torch.tensor(word_w2v.wv[word])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "next, W_projection for Linear layer (hidden_size*4, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_word2index_label,vocabulary_index2word_label = create_vocabulary_label_pre_split(training_data_path=training_data_path, validation_data_path=validation_data_path, testing_data_path=testing_data_path, name_scope=dataset + \"-HAN\") # keep a distinct name scope for each model and each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_w2v_400 = Word2Vec.load(word2vec_label_path_400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8686"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label_w2v_400.wv.key_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "bound = np.sqrt(6.0) / np.sqrt(num_classes + hidden_size * 4)\n",
    "W_linear = torch.rand((num_classes, hidden_size*4)) * 2 * bound - bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'401.9'"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_index2word_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_classes):\n",
    "    label = vocabulary_index2word_label[i]\n",
    "    if label in label_w2v_400.wv.key_to_index:\n",
    "        W_linear[i, :] = torch.tensor(label_w2v_400.wv[label])\n",
    "    else:\n",
    "        print(i, label, 'not in vocab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lastly, the word level and sentence level context vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_w2v_200 = Word2Vec.load(word2vec_label_path_200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_context_vector = torch.rand((num_classes, hidden_size * 2)) * 2* bound - bound\n",
    "sentence_context_vector = torch.rand((num_classes, hidden_size * 2)) * 2* bound - bound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(num_classes):\n",
    "    label = vocabulary_index2word_label[i]\n",
    "    if label in label_w2v_200.wv.key_to_index:\n",
    "        word_context_vector[i, :] = torch.tensor(label_w2v_200.wv[label])\n",
    "        sentence_context_vector[i, :] = torch.tensor(label_w2v_200.wv[label])\n",
    "    else:\n",
    "        print(i, label, 'not in vocab')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HierarchicalAttentionNetwork(vocab_size=vocab_size, embed_size=embed_size, hidden_size=hidden_size, num_sentences=num_sentences, sentence_length=sentence_length, num_classes=num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "W torch.Size([50, 400]) True\n",
      "b torch.Size([50]) True\n",
      "embeddings.weight torch.Size([150854, 100]) True\n",
      "word_gru.weight_ih_l0 torch.Size([300, 100]) True\n",
      "word_gru.weight_hh_l0 torch.Size([300, 100]) True\n",
      "word_gru.bias_ih_l0 torch.Size([300]) True\n",
      "word_gru.bias_hh_l0 torch.Size([300]) True\n",
      "sentence_gru.weight_ih_l0 torch.Size([600, 200]) True\n",
      "sentence_gru.weight_hh_l0 torch.Size([600, 200]) True\n",
      "sentence_gru.bias_ih_l0 torch.Size([600]) True\n",
      "sentence_gru.bias_hh_l0 torch.Size([600]) True\n",
      "word_attention.context_vector torch.Size([50, 200]) True\n",
      "word_attention.linear.weight torch.Size([200, 200]) True\n",
      "word_attention.linear.bias torch.Size([200]) True\n",
      "sentence_attention.context_vector torch.Size([50, 200]) True\n",
      "sentence_attention.linear.weight torch.Size([200, 400]) True\n",
      "sentence_attention.linear.bias torch.Size([200]) True\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(n, p.shape, p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    model.embeddings.weight.data.copy_(embeddings)\n",
    "    model.word_attention.context_vector.data.copy_(word_context_vector)\n",
    "    model.sentence_attention.context_vector.data.copy_(sentence_context_vector)\n",
    "    model.W.data.copy_(W_linear)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test model loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HierarchicalAttentionNetwork(vocab_size=vocab_size, embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, num_sentences=NUM_SENTENCES, sentence_length=SENTENCE_LENGTH, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"./checkpoints/HLAN_LE_20epochs.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HierarchicalAttentionNetwork(\n",
       "  (embeddings): Embedding(150854, 100)\n",
       "  (word_gru): GRU(100, 100)\n",
       "  (sentence_gru): GRU(200, 200)\n",
       "  (word_attention): AttentionPerLabelWordLevel(\n",
       "    (linear): Linear(in_features=200, out_features=200, bias=True)\n",
       "  )\n",
       "  (sentence_attention): AttentionPerLabelSentenceLevel(\n",
       "    (linear): Linear(in_features=400, out_features=200, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd4h",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
