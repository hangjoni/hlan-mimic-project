{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "# import constants\n",
    "from constants import *\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import load_data_multilabel_pre_split , create_dataloaders, initialization_using_word2vec, create_subset_dataloader, get_micro_metrics, create_vocabulary_label_pre_split, create_vocabulary\n",
    "from HAN_model import HierarchicalAttentionNetwork\n",
    "\n",
    "from metrics import *\n",
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n",
      "load_data.started...\n",
      "load_data_multilabel_new.data_path: ../datasets/data/train_50_eamc.csv\n",
      "load_data.ended...\n",
      "load_data.started...\n",
      "load_data_multilabel_new.data_path: ../datasets/data/dev_50_eamc.csv\n",
      "load_data.ended...\n",
      "shuffled training data\n"
     ]
    }
   ],
   "source": [
    "train_dataloader, valid_dataloader, vocab_size = create_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HierarchicalAttentionNetwork(vocab_size=vocab_size, embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, num_sentences=NUM_SENTENCES, sentence_length=SENTENCE_LENGTH, num_classes=NUM_CLASSES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    }
   ],
   "source": [
    "model = initialization_using_word2vec(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000005)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first training script, without initialization.\n",
    "this training script has one major fault: we forgot to reset gradients at each minibatch! Keeping here for reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 loss 52.44690704345703\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:32,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 loss 36.18838847767223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [00:58,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 20 loss 33.24757476080032\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [01:24,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 30 loss 32.721970650457564\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [01:50,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 40 loss 32.93682638028773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [02:16,  2.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 50 loss 31.958648382448683\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [02:42,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 60 loss 31.103213200803662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [03:09,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 70 loss 30.552288727021555\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [03:40,  2.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 80 loss 30.282272644984868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [04:06,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 90 loss 29.822059254069906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [04:39,  3.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 100 loss 29.609745006750124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111it [05:09,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 110 loss 29.421181876380164\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [05:35,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 120 loss 29.341002503702462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [06:02,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 130 loss 29.239765793312596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "141it [06:29,  2.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 140 loss 29.16025330834355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [07:03,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 150 loss 29.132182456010224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161it [07:37,  3.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 160 loss 28.99819346836635\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171it [08:10,  3.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 170 loss 28.91697088319656\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "181it [08:39,  2.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 180 loss 28.848535927619725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "191it [09:05,  2.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 190 loss 28.810952900591946\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [09:35,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 200 loss 28.856003946332788\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "211it [10:08,  3.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 210 loss 28.91458556550374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [10:43,  3.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 220 loss 29.132748237022987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [11:18,  3.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 230 loss 29.444872472193335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [11:53,  3.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 240 loss 29.84288608978398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "251it [12:22,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 250 loss 30.278502186930986\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "252it [12:25,  2.96s/it]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "shape '[32, 2500, 100]' is invalid for input of size 500000",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/train_playground.ipynb Cell 6\u001b[0m line \u001b[0;36m6\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/train_playground.ipynb#W5sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m losses \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/train_playground.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, (x, y) \u001b[39min\u001b[39;00m tqdm(\u001b[39menumerate\u001b[39m(dataloader)):\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/train_playground.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m     y_hat \u001b[39m=\u001b[39m model(x)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/train_playground.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m     loss \u001b[39m=\u001b[39m criterion(y_hat, y)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/train_playground.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m     loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/anaconda3/envs/bd4h/lib/python3.11/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_compiled_call_impl(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call_impl(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/anaconda3/envs/bd4h/lib/python3.11/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1529\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/HAN_model.py:182\u001b[0m, in \u001b[0;36mHierarchicalAttentionNetwork.forward\u001b[0;34m(self, input_tensor)\u001b[0m\n\u001b[1;32m    180\u001b[0m output_words_right2left_reshaped \u001b[39m=\u001b[39m output_words_right2left\u001b[39m.\u001b[39mview(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_sentences, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msentence_length, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39membed_size)\n\u001b[1;32m    181\u001b[0m output_words_right2left_reshaped_reversed \u001b[39m=\u001b[39m output_words_right2left_reshaped\u001b[39m.\u001b[39mflip(dims\u001b[39m=\u001b[39m[\u001b[39m2\u001b[39m])\n\u001b[0;32m--> 182\u001b[0m output_words_right2left_reversed \u001b[39m=\u001b[39m output_words_right2left_reshaped_reversed\u001b[39m.\u001b[39;49mview(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_size, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnum_sentences \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentence_length, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49membed_size)\n\u001b[1;32m    183\u001b[0m output_words \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((output_words_left2right, output_words_right2left_reversed), dim\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m)\n\u001b[1;32m    185\u001b[0m \u001b[39m# word_level attention\u001b[39;00m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[32, 2500, 100]' is invalid for input of size 500000"
     ]
    }
   ],
   "source": [
    "# train one epoch\n",
    "from tqdm import tqdm\n",
    "\n",
    "losses = []\n",
    "for i, (x, y) in tqdm(enumerate(dataloader)):\n",
    "    y_hat = model(x)\n",
    "    loss = criterion(y_hat, y)\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print('iter', i, 'loss', np.array(losses).mean())\n",
    "print('done 1 epoch', 'loss:', np.array(losses).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:04,  4.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 loss 75.09092712402344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:37,  3.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 loss 49.521841916170985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [01:04,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 20 loss 43.32634353637695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [01:32,  2.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 30 loss 40.6211912093624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [02:02,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 40 loss 39.0463952320378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [02:28,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 50 loss 37.02092331531001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [02:57,  3.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 60 loss 35.387808909181686\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [03:29,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 70 loss 34.229467929249076\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [03:56,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 80 loss 33.58679429984387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [04:24,  2.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 90 loss 32.963436902224366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [04:49,  2.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 100 loss 32.51199756282391\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111it [05:14,  2.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 110 loss 32.14766309927176\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [05:39,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 120 loss 31.86359189561576\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [06:05,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 130 loss 31.611873408310284\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "141it [06:31,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 140 loss 31.395271436542483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [06:57,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 150 loss 31.239010918219357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161it [07:23,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 160 loss 31.03779889930109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171it [07:49,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 170 loss 30.91952669690227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "181it [08:15,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 180 loss 30.828073501586914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "191it [08:41,  2.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 190 loss 30.74624914398992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [09:07,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 200 loss 30.774566384690317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "211it [09:33,  2.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 210 loss 30.809242781869607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [10:00,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 220 loss 30.96526320271902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [10:27,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 230 loss 31.193378225549473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [10:54,  2.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 240 loss 31.55847540732736\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "251it [11:20,  2.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 250 loss 31.937302692002984\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253it [11:23,  2.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1 epoch loss: 32.009809041682914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train one epoch\n",
    "from tqdm import tqdm\n",
    "\n",
    "losses = []\n",
    "for i, (x, y) in tqdm(enumerate(dataloader)):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(x)\n",
    "    loss = criterion(y_hat, y)\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print('iter', i, 'loss', np.array(losses).mean())\n",
    "print('done 1 epoch', 'loss:', np.array(losses).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the model after 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:46<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "actuals = []\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(valid_dataloader):\n",
    "        y_hat = model(x)\n",
    "        probs = F.softmax(y_hat, dim=1)\n",
    "\n",
    "        label = torch.argmax(probs, dim=1)\n",
    "        label_y = torch.argmax(y, dim=1)\n",
    "\n",
    "        preds.append(list(label.numpy()))\n",
    "        actuals.append(list(label_y.numpy()))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = np.concatenate(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = np.concatenate(actuals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3801787164906271,\n",
       " 0.057303783519039336,\n",
       " 0.07258064516128919,\n",
       " 0.06404379062606823)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc, prec, rec, f1 = all_macro(preds, actuals)\n",
    "acc, prec, rec, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4259376986649714 0.7745664739884393\n"
     ]
    }
   ],
   "source": [
    "precision, recall = calculate_precision_recall(preds, actuals)\n",
    "print(precision, recall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.024237049531897863\n",
      "Recall: 0.01719362244931067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hungryfoolish/anaconda3/envs/bd4h/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/hungryfoolish/anaconda3/envs/bd4h/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1471: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score\n",
    "\n",
    "# Assume y_true and y_pred are your actual and predicted labels respectively\n",
    "# y_true = ...\n",
    "# y_pred = ...\n",
    "\n",
    "precision = precision_score(preds, actuals, average='macro')  # for multi-class classification\n",
    "recall = recall_score(preds, actuals, average='macro')  # for multi-class classification\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision: 0.22822631913541006\n",
      "Recall: 0.22822631913541006\n"
     ]
    }
   ],
   "source": [
    "precision = precision_score(preds, actuals, average='micro')  # for multi-class classification\n",
    "recall = recall_score(preds, actuals, average='micro')  # for multi-class classification\n",
    "\n",
    "print(f\"Precision: {precision}\")\n",
    "print(f\"Recall: {recall}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training one epoch with smart initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:05,  5.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 loss 22.66522979736328\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "11it [00:37,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 loss 17.240951017899945\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "21it [01:05,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 20 loss 16.972276778448197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "31it [01:32,  2.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 30 loss 17.674793612572454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "41it [01:59,  2.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 40 loss 18.54887045883551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "51it [02:27,  2.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 50 loss 18.660027148676853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "61it [02:56,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 60 loss 18.769797246964252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "71it [03:22,  2.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 70 loss 18.92314792686785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "81it [03:50,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 80 loss 19.220837534209828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "91it [04:20,  2.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 90 loss 19.411412794511396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "101it [04:48,  2.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 100 loss 19.68570909405699\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "111it [05:21,  3.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 110 loss 19.983266967910904\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "121it [05:54,  3.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 120 loss 20.294265494858923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "131it [06:23,  2.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 130 loss 20.604145006369087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "141it [06:55,  3.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 140 loss 20.911784801077335\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "151it [07:23,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 150 loss 21.23349266810133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "161it [07:50,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 160 loss 21.453838336541786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "171it [08:18,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 170 loss 21.71918661552563\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "181it [08:45,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 180 loss 21.973330429245753\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "191it [09:13,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 190 loss 22.211702636399195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "201it [09:41,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 200 loss 22.508781490041248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "211it [10:09,  2.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 210 loss 22.759959107891643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "221it [10:37,  2.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 220 loss 23.062788950372067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "231it [11:05,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 230 loss 23.33391928569579\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "241it [11:33,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 240 loss 23.66225935908274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "251it [12:01,  2.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 250 loss 24.02995038887419\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253it [12:04,  2.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1 epoch loss: 24.120068244783305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train one epoch\n",
    "from tqdm import tqdm\n",
    "\n",
    "losses = []\n",
    "for i, (x, y) in tqdm(enumerate(train_dataloader)):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(x)\n",
    "    loss = criterion(y_hat, y)\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print('iter', i, 'loss', np.array(losses).mean())\n",
    "print('done 1 epoch', 'loss:', np.array(losses).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "loss starts out much lower (less than 40% of the model without initialization)\n",
    "However loss didn't reduce after 1 epoch. To look into:\n",
    "- gradient clipping\n",
    "- learning rate scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = SummaryWriter(\"./logs/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 loss 18.12038803100586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:37,  3.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 loss 19.25037332014604\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [01:07,  3.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 20 loss 20.473399389357795\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [01:43,  3.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 30 loss 21.38740570314469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [02:17,  3.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 40 loss 22.757802498049852\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [02:46,  3.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1 epoch loss: 23.77406593322754\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# train one epoch\n",
    "from tqdm import tqdm\n",
    "\n",
    "losses = []\n",
    "for i, (x, y) in tqdm(enumerate(valid_dataloader)):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(x)\n",
    "    loss = criterion(y_hat, y)\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    if i % 10 == 0:\n",
    "        print('iter', i, 'loss', np.array(losses).mean())\n",
    "\n",
    "        for tag, value in model.named_parameters():\n",
    "            if value.grad is not None:\n",
    "                logger.add_histogram(tag + \"/grad\", value.grad.cpu(), i*10)\n",
    "\n",
    "print('done 1 epoch', 'loss:', np.array(losses).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:5roqs4ns) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁▅▂▁▁▂▂▄▂▄▄▄▃▄▆▃▃▃▅▄▅▄▄▆▅▇▄▆▆▆▅▇▇▆▇█▆▇▆▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>21.62302</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">woven-water-5</strong> at: <a href='https://wandb.ai/hangjoni/bd4h-project/runs/5roqs4ns' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project/runs/5roqs4ns</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231122_111819-5roqs4ns/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:5roqs4ns). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/wandb/run-20231122_112843-eoll5ip6</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hangjoni/bd4h-project/runs/eoll5ip6' target=\"_blank\">misty-snowflake-6</a></strong> to <a href='https://wandb.ai/hangjoni/bd4h-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hangjoni/bd4h-project' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hangjoni/bd4h-project/runs/eoll5ip6' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project/runs/eoll5ip6</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 loss 19.893186569213867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:44,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 loss 22.45019635287198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [01:24,  3.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 20 loss 24.543202173142205\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [01:56,  3.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 30 loss 25.426361330093876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [02:30,  3.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 40 loss 26.752272256990757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [03:07,  3.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1 epoch loss: 27.778998069763183\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = HierarchicalAttentionNetwork(vocab_size=vocab_size, embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, num_sentences=NUM_SENTENCES, sentence_length=SENTENCE_LENGTH, num_classes=NUM_CLASSES)\n",
    "model = initialization_using_word2vec(model)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000005)\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"bd4h-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.000005,\n",
    "    \"architecture\": \"HLAN+LE\",\n",
    "    \"dataset\": \"mimic-50\",\n",
    "    \"epochs\": 1,\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.watch(model, criterion, log='all', log_freq=1)\n",
    "\n",
    "logger = SummaryWriter(\"./logs/\")\n",
    "\n",
    "losses = []\n",
    "for i, (x, y) in tqdm(enumerate(valid_dataloader)):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(x)\n",
    "    loss = criterion(y_hat, y)\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    wandb.log({'loss': loss.item()})\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print('iter', i, 'loss', np.array(losses).mean())\n",
    "\n",
    "    for layer, (tag, value) in enumerate(model.named_parameters()):\n",
    "        logger.add_histogram(f\"grad/{layer}.{tag}\", value.grad.cpu(), i)\n",
    "\n",
    "print('done 1 epoch', 'loss:', np.array(losses).mean())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0014)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.weight.data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 6.1396e-03,  1.3556e-03, -3.6092e-04,  ..., -5.0547e-03,\n",
       "         -3.1368e-03,  2.8457e-03],\n",
       "        [ 2.0926e+00, -4.5464e-01,  1.8291e+00,  ..., -3.2387e+00,\n",
       "          2.0335e+00,  1.9512e+00],\n",
       "        [ 1.2300e+00,  1.4408e-01,  4.1557e-01,  ..., -1.0325e+00,\n",
       "         -3.5222e-01,  1.2765e+00],\n",
       "        ...,\n",
       "        [-1.0968e-02, -9.3574e-03,  4.2765e-03,  ..., -9.8647e-03,\n",
       "         -8.0069e-03, -9.9252e-03],\n",
       "        [-1.9467e-02, -5.4372e-03,  3.0623e-03,  ...,  9.0115e-02,\n",
       "         -6.0075e-02, -1.6655e-02],\n",
       "        [-1.8207e-02,  7.9990e-03,  9.5015e-03,  ...,  3.4038e-02,\n",
       "         -1.3660e-02, -8.8746e-03]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[ 7.3915e-04,  4.0171e-03,  5.6544e-03,  ..., -4.6091e-03,\n",
       "         -6.1196e-03,  8.1953e-04],\n",
       "        [ 2.0924e+00, -4.5478e-01,  1.8291e+00,  ..., -3.2387e+00,\n",
       "          2.0336e+00,  1.9510e+00],\n",
       "        [ 1.2299e+00,  1.4384e-01,  4.1572e-01,  ..., -1.0323e+00,\n",
       "         -3.5227e-01,  1.2763e+00],\n",
       "        ...,\n",
       "        [-1.0968e-02, -9.3574e-03,  4.2765e-03,  ..., -9.8647e-03,\n",
       "         -8.0069e-03, -9.9252e-03],\n",
       "        [-1.9467e-02, -5.4372e-03,  3.0623e-03,  ...,  9.0115e-02,\n",
       "         -6.0075e-02, -1.6655e-02],\n",
       "        [-1.8207e-02,  7.9990e-03,  9.5015e-03,  ...,  3.4038e-02,\n",
       "         -1.3660e-02, -8.8746e-03]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2 = HierarchicalAttentionNetwork(vocab_size=vocab_size, embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, num_sentences=NUM_SENTENCES, sentence_length=SENTENCE_LENGTH, num_classes=NUM_CLASSES)\n",
    "model2 = initialization_using_word2vec(model2)\n",
    "model2.embeddings.weight.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.0014)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.embeddings.weight.data.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.0873e+00, -1.2834e+00, -3.4314e+00,  2.7273e+00, -1.1918e+00,\n",
       "        -1.5990e-01, -2.5308e+00,  4.2257e-01, -3.1923e-01,  2.4978e+00,\n",
       "        -1.2897e-01,  1.7628e+00, -2.2354e-02,  4.0559e+00,  2.1190e-02,\n",
       "         8.5813e-01,  8.9449e-01,  2.1671e-01,  4.0218e-01, -2.7727e-01,\n",
       "         1.5968e+00, -1.1943e+00, -1.3494e+00,  2.7491e+00,  1.9064e+00,\n",
       "        -4.4494e-01,  1.2601e-01,  1.3564e+00, -1.1144e+00,  5.0334e-01,\n",
       "         1.3037e-01,  9.4918e-01,  3.2484e+00, -5.2825e-01, -6.0826e-03,\n",
       "         1.9672e+00,  6.7840e-01,  1.4207e+00,  3.2294e+00,  1.4503e+00,\n",
       "         3.3367e+00, -3.9044e-02, -2.7064e+00,  7.6135e-01,  2.6548e+00,\n",
       "         1.3578e+00, -2.3968e+00,  1.9119e-01,  1.5119e+00, -8.1424e-01,\n",
       "        -5.1204e-01, -1.4608e+00, -1.4920e+00,  1.6127e+00, -2.6102e+00,\n",
       "        -1.9838e+00, -1.5403e+00, -2.4108e+00,  2.4294e+00,  5.9733e-01,\n",
       "         7.6137e-01,  2.5147e+00, -5.3443e-01, -5.3333e-01, -3.2919e+00,\n",
       "        -2.8149e+00, -2.2459e+00, -2.8667e-01,  4.5187e+00,  1.1866e+00,\n",
       "        -5.5509e+00, -1.4151e+00,  8.9300e-01,  1.5448e-01, -2.6520e+00,\n",
       "         1.0118e+00, -2.8227e+00,  1.8370e+00, -1.2448e+00, -4.7908e-01,\n",
       "        -1.4100e+00, -1.3817e+00,  1.1041e+00, -3.3302e+00,  4.5660e+00,\n",
       "         1.7587e+00,  2.5919e+00,  2.6506e+00, -1.6261e+00,  1.4778e+00,\n",
       "         1.2609e+00,  3.6652e+00,  2.1986e+00, -1.6321e-01,  1.7512e+00,\n",
       "        -4.3288e+00,  1.0945e+00,  8.7596e+00,  1.9153e+00, -5.1503e-01])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model2.embeddings.weight.data[10,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-3.0871e+00, -1.2833e+00, -3.4314e+00,  2.7275e+00, -1.1919e+00,\n",
       "        -1.5964e-01, -2.5308e+00,  4.2277e-01, -3.1932e-01,  2.4977e+00,\n",
       "        -1.2909e-01,  1.7629e+00, -2.2438e-02,  4.0560e+00,  2.0990e-02,\n",
       "         8.5792e-01,  8.9459e-01,  2.1686e-01,  4.0219e-01, -2.7713e-01,\n",
       "         1.5968e+00, -1.1944e+00, -1.3493e+00,  2.7493e+00,  1.9063e+00,\n",
       "        -4.4497e-01,  1.2614e-01,  1.3563e+00, -1.1143e+00,  5.0354e-01,\n",
       "         1.3013e-01,  9.4936e-01,  3.2485e+00, -5.2824e-01, -6.2785e-03,\n",
       "         1.9672e+00,  6.7821e-01,  1.4209e+00,  3.2293e+00,  1.4501e+00,\n",
       "         3.3366e+00, -3.9110e-02, -2.7065e+00,  7.6147e-01,  2.6547e+00,\n",
       "         1.3579e+00, -2.3970e+00,  1.9140e-01,  1.5119e+00, -8.1431e-01,\n",
       "        -5.1223e-01, -1.4610e+00, -1.4919e+00,  1.6128e+00, -2.6103e+00,\n",
       "        -1.9840e+00, -1.5402e+00, -2.4107e+00,  2.4292e+00,  5.9744e-01,\n",
       "         7.6122e-01,  2.5147e+00, -5.3418e-01, -5.3354e-01, -3.2918e+00,\n",
       "        -2.8148e+00, -2.2456e+00, -2.8683e-01,  4.5188e+00,  1.1867e+00,\n",
       "        -5.5510e+00, -1.4151e+00,  8.9314e-01,  1.5450e-01, -2.6519e+00,\n",
       "         1.0118e+00, -2.8225e+00,  1.8367e+00, -1.2450e+00, -4.7908e-01,\n",
       "        -1.4102e+00, -1.3817e+00,  1.1042e+00, -3.3302e+00,  4.5660e+00,\n",
       "         1.7587e+00,  2.5918e+00,  2.6504e+00, -1.6260e+00,  1.4776e+00,\n",
       "         1.2610e+00,  3.6653e+00,  2.1985e+00, -1.6307e-01,  1.7512e+00,\n",
       "        -4.3287e+00,  1.0947e+00,  8.7596e+00,  1.9152e+00, -5.1511e-01])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.embeddings.weight.data[10,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "value of embeddings didn't change much after training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(train_dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 1., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [1., 0., 0.,  ..., 0., 1., 1.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [1., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 50])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 3.,  3.,  1.,  4.,  6.,  7.,  4.,  6., 10.,  4.,  9.,  5.,  6.,  2.,\n",
       "         4.,  2.,  3.,  3.,  6.,  1.,  2., 13.,  5.,  3., 12.,  2.,  3.,  5.,\n",
       "         1.,  9.,  3.,  2.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.sum(dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we used the wrong loss function! Each y is a multi-hot label, so in stead of CrossEntropyLoss we need to use BCEWithLogitsLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:eoll5ip6) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁▄▁▁▁▂▂▄▂▄▅▄▃▄▇▃▃▃▅▄▅▄▄▆▅▆▄▆▆▆▅▆▇▇▇█▆▇▇▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>21.271</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">misty-snowflake-6</strong> at: <a href='https://wandb.ai/hangjoni/bd4h-project/runs/eoll5ip6' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project/runs/eoll5ip6</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231122_112843-eoll5ip6/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:eoll5ip6). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/wandb/run-20231122_140940-nynlpo05</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hangjoni/bd4h-project/runs/nynlpo05' target=\"_blank\">glad-forest-7</a></strong> to <a href='https://wandb.ai/hangjoni/bd4h-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hangjoni/bd4h-project' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hangjoni/bd4h-project/runs/nynlpo05' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project/runs/nynlpo05</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 0 loss 0.831281840801239\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "10it [00:39,  3.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 10 loss 0.8375096754594282\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "20it [01:25,  4.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 20 loss 0.8310460930778867\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "30it [01:59,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 30 loss 0.8223150814733198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "40it [02:36,  3.83s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iter 40 loss 0.8104217706657038\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "50it [03:10,  3.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done 1 epoch loss: 0.7969258832931518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = HierarchicalAttentionNetwork(vocab_size=vocab_size, embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, num_sentences=NUM_SENTENCES, sentence_length=SENTENCE_LENGTH, num_classes=NUM_CLASSES)\n",
    "model = initialization_using_word2vec(model)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.000005)\n",
    "\n",
    "wandb.init(\n",
    "    # set the wandb project where this run will be logged\n",
    "    project=\"bd4h-project\",\n",
    "    \n",
    "    # track hyperparameters and run metadata\n",
    "    config={\n",
    "    \"learning_rate\": 0.000005,\n",
    "    \"architecture\": \"HLAN+LE\",\n",
    "    \"dataset\": \"mimic-50\",\n",
    "    \"epochs\": 1,\n",
    "    \"loss\": \"BCEWithLogitsLoss\"\n",
    "    }\n",
    ")\n",
    "\n",
    "wandb.watch(model, criterion, log='all', log_freq=1)\n",
    "\n",
    "logger = SummaryWriter(\"./logs/\")\n",
    "\n",
    "losses = []\n",
    "for i, (x, y) in tqdm(enumerate(valid_dataloader)):\n",
    "    optimizer.zero_grad()\n",
    "    y_hat = model(x)\n",
    "    loss = criterion(y_hat, y)\n",
    "    loss.backward()\n",
    "    losses.append(loss.item())\n",
    "    optimizer.step()\n",
    "    wandb.log({'loss': loss.item()})\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        print('iter', i, 'loss', np.array(losses).mean())\n",
    "\n",
    "    for layer, (tag, value) in enumerate(model.named_parameters()):\n",
    "        logger.add_histogram(f\"grad/{layer}.{tag}\", value.grad.cpu(), i)\n",
    "\n",
    "print('done 1 epoch', 'loss:', np.array(losses).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "yay! now loss did go down during training!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit on a few data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "\n",
    "def create_subset_dataloader(original_loader, num_samples=10):\n",
    "    \"\"\"\n",
    "    Create a new DataLoader with a subset of the original data.\n",
    "\n",
    "    Parameters:\n",
    "    - original_loader (DataLoader): The original DataLoader.\n",
    "    - num_samples (int): Number of samples to include in the subset.\n",
    "\n",
    "    Returns:\n",
    "    - DataLoader: A new DataLoader with the subset of data.\n",
    "    \"\"\"\n",
    "    # Get the original dataset from the DataLoader\n",
    "    original_dataset = original_loader.dataset\n",
    "\n",
    "    # Check if the desired number of samples is not more than the dataset size\n",
    "    num_samples = min(num_samples, len(original_dataset))\n",
    "\n",
    "    # Create a subset\n",
    "    subset_indices = torch.arange(num_samples)\n",
    "    subset = Subset(original_dataset, subset_indices)\n",
    "\n",
    "    # Create a new DataLoader with the subset\n",
    "    subset_loader = DataLoader(subset, batch_size=original_loader.batch_size, shuffle=False)\n",
    "\n",
    "    return subset_loader\n",
    "\n",
    "# Example usage\n",
    "# Assuming original_loader is your existing DataLoader\n",
    "new_loader = create_subset_dataloader(train_dataloader, num_samples=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "# import constants\n",
    "from constants import *\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from utils import create_vocabulary_label_pre_split, create_vocabulary\n",
    "from utils import load_data_multilabel_pre_split , create_dataloaders, initialization_using_word2vec\n",
    "from HAN_model import HierarchicalAttentionNetwork\n",
    "\n",
    "from metrics import *\n",
    "\n",
    "\n",
    "def train(dataloader, vocab_size, epochs=1, lr=0.0005, log=True):\n",
    "    model = HierarchicalAttentionNetwork(vocab_size=vocab_size, embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, num_sentences=NUM_SENTENCES, sentence_length=SENTENCE_LENGTH, num_classes=NUM_CLASSES)\n",
    "    model = initialization_using_word2vec(model)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "    if log:\n",
    "        wandb.init(\n",
    "            # set the wandb project where this run will be logged\n",
    "            project=\"bd4h-project\",\n",
    "            \n",
    "            # track hyperparameters and run metadata\n",
    "            config={\n",
    "            \"learning_rate\": lr,\n",
    "            \"architecture\": \"HLAN+LE\",\n",
    "            \"dataset\": \"mimic-50\",\n",
    "            \"epochs\": 1,\n",
    "            \"loss\": \"BCEWithLogitsLoss\"\n",
    "            }\n",
    "        )\n",
    "        wandb.watch(model, criterion, log='all', log_freq=1)\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        losses = []\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "            \n",
    "            if log:\n",
    "                wandb.log({'loss': loss.item()})\n",
    "                for layer, (tag, value) in enumerate(model.named_parameters()):\n",
    "                    logger.add_histogram(f\"grad/{layer}.{tag}\", value.grad.cpu(), i)\n",
    "            \n",
    "        print('epoch', epoch, 'loss', np.array(losses).mean())\n",
    "        scheduler.step(np.array(losses).mean())\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train import train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:00<00:11,  8.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.8193429708480835\n",
      "epoch 1 loss 0.4199869632720947\n",
      "epoch 2 loss 0.25279635190963745\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:00<00:09,  9.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 loss 0.17087604105472565\n",
      "epoch 4 loss 0.13766346871852875\n",
      "epoch 5 loss 0.11568380147218704\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [00:00<00:08, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 loss 0.10351071506738663\n",
      "epoch 7 loss 0.09372936934232712\n",
      "epoch 8 loss 0.05058024078607559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [00:01<00:08, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 loss 0.05220650136470795\n",
      "epoch 10 loss 0.06845586001873016\n",
      "epoch 11 loss 0.035004034638404846\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [00:01<00:07, 11.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 loss 0.027773218229413033\n",
      "epoch 13 loss 0.025817571207880974\n",
      "epoch 14 loss 0.03080725483596325\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [00:01<00:07, 10.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 loss 0.02734314650297165\n",
      "epoch 16 loss 0.024270500987768173\n",
      "epoch 17 loss 0.02255089208483696\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [00:01<00:07, 11.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 loss 0.01995673216879368\n",
      "epoch 19 loss 0.016502315178513527\n",
      "epoch 20 loss 0.014533953741192818\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [00:02<00:06, 11.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 loss 0.012399119324982166\n",
      "epoch 22 loss 0.009690814651548862\n",
      "epoch 23 loss 0.00843256525695324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [00:02<00:06, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 loss 0.007241958752274513\n",
      "epoch 25 loss 0.006641285493969917\n",
      "epoch 26 loss 0.006502771284431219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [00:02<00:06, 10.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 loss 0.006486282218247652\n",
      "epoch 28 loss 0.006434093229472637\n",
      "epoch 29 loss 0.0063546388410031796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [00:03<00:06, 11.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 loss 0.006206745281815529\n",
      "epoch 31 loss 0.006082253064960241\n",
      "epoch 32 loss 0.006024539936333895\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [00:03<00:05, 10.95it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33 loss 0.006009091157466173\n",
      "epoch 34 loss 0.0059487842954695225\n",
      "epoch 35 loss 0.005876206327229738\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [00:03<00:05, 10.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36 loss 0.005800621118396521\n",
      "epoch 37 loss 0.005745928268879652\n",
      "epoch 38 loss 0.005706793628633022\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [00:03<00:05, 10.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 loss 0.0056708138436079025\n",
      "epoch 40 loss 0.0056336005218327045\n",
      "epoch 41 loss 0.005591763649135828\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [00:04<00:05, 10.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42 loss 0.005544483195990324\n",
      "epoch 43 loss 0.005497067701071501\n",
      "epoch 44 loss 0.005453088786453009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [00:04<00:04, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45 loss 0.00541327428072691\n",
      "epoch 46 loss 0.005376121960580349\n",
      "epoch 47 loss 0.005340891424566507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [00:04<00:04, 11.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48 loss 0.005304434336721897\n",
      "epoch 49 loss 0.005266610998660326\n",
      "epoch 50 loss 0.0052277701906859875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [00:04<00:04, 10.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51 loss 0.0051885140128433704\n",
      "epoch 52 loss 0.005149777512997389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [00:05<00:04, 10.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53 loss 0.005111894570291042\n",
      "epoch 54 loss 0.00507454015314579\n",
      "epoch 55 loss 0.005037682130932808\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [00:05<00:03, 10.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56 loss 0.005001228302717209\n",
      "epoch 57 loss 0.004965164698660374\n",
      "epoch 58 loss 0.004929390270262957\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [00:05<00:03, 10.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59 loss 0.004893905017524958\n",
      "epoch 60 loss 0.004858673084527254\n",
      "epoch 61 loss 0.004823667928576469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [00:06<00:03, 10.96it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62 loss 0.004788875114172697\n",
      "epoch 63 loss 0.004754288122057915\n",
      "epoch 64 loss 0.004719865974038839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [00:06<00:02, 11.05it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65 loss 0.004685614258050919\n",
      "epoch 66 loss 0.004651515278965235\n",
      "epoch 67 loss 0.004617564845830202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [00:06<00:02, 10.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68 loss 0.0045837704092264175\n",
      "epoch 69 loss 0.004550142679363489\n",
      "epoch 70 loss 0.004516692366451025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [00:06<00:02, 10.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71 loss 0.004483422264456749\n",
      "epoch 72 loss 0.004450351465493441\n",
      "epoch 73 loss 0.00441746786236763\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [00:07<00:02, 11.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74 loss 0.0043847751803696156\n",
      "epoch 75 loss 0.0043522659689188\n",
      "epoch 76 loss 0.0043199616484344006\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [00:07<00:01, 11.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77 loss 0.004287846852093935\n",
      "epoch 78 loss 0.004255935084074736\n",
      "epoch 79 loss 0.0042241946794092655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [00:07<00:01, 11.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80 loss 0.004192637279629707\n",
      "epoch 81 loss 0.004161263816058636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [00:07<00:01, 10.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82 loss 0.00413003284484148\n",
      "epoch 83 loss 0.004098784644156694\n",
      "epoch 84 loss 0.004064661450684071\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [00:08<00:01, 10.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85 loss 0.0040285480208694935\n",
      "epoch 86 loss 0.003990148659795523\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [00:08<00:01,  9.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87 loss 0.003945787902921438\n",
      "epoch 88 loss 0.0038994222413748503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [00:08<00:00, 10.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89 loss 0.0038539450615644455\n",
      "epoch 90 loss 0.0038117943331599236\n",
      "epoch 91 loss 0.0037730804178863764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [00:08<00:00, 10.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92 loss 0.0037333103828132153\n",
      "epoch 93 loss 0.003689634846523404\n",
      "epoch 94 loss 0.003645260352641344\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [00:09<00:00, 10.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95 loss 0.003603600896894932\n",
      "epoch 96 loss 0.003564758924767375\n",
      "epoch 97 loss 0.003527594730257988\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:09<00:00, 10.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98 loss 0.0034902903717011213\n",
      "epoch 99 loss 0.0034513953141868114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train(new_loader, vocab_size, epochs=100, lr=0.005, log=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([6])\n",
      "tensor([48])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(new_loader))\n",
    "y_hat = model(x)\n",
    "print(y.argmax(dim=1))\n",
    "print(y_hat.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-31.5819, -12.2134, -11.6357, -12.3696, -15.3418, -15.8302,   9.2258,\n",
       "         -22.1400, -25.6424, -18.1387, -11.7790, -13.0992, -11.1329, -13.5590,\n",
       "         -22.6651, -12.9194,  -8.6934, -12.4655, -18.7481, -21.6440, -11.1930,\n",
       "         -11.3491, -11.6307,  -9.9779, -10.5721, -13.8085, -11.0767, -12.3561,\n",
       "         -11.0915, -14.5768, -13.5439, -25.0359, -14.6869, -21.9130,  -9.2226,\n",
       "         -10.2231,  -9.9000,   1.6860, -26.5688, -15.5023, -16.1322, -23.2063,\n",
       "         -13.3837, -42.9854, -15.0577, -15.3846, -13.0794, -14.0496,  16.9560,\n",
       "         -19.7838]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(torch.sigmoid(y_hat) > 0.01, torch.ones(y_hat.shape), torch.zeros(y_hat.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we have successfully overfit one data point!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# overfit 10 data points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "ten_loader = create_subset_dataloader(train_dataloader, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_loader = create_subset_dataloader(valid_dataloader, num_samples=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n",
      "Created directory to save model checkpoint at ../checkpoints/WfsQP\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.04it/s]00:00<?, ?it/s]\n",
      "1it [00:00,  3.21it/s]\n",
      " 20%|██        | 1/5 [00:01<00:05,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 train loss: 0.8429926633834839\n",
      "Epoch 0 valid loss: 0.9579273462295532\n",
      "Epoch 0 valid accuracy: 0.025974025974025976\n",
      "Epoch 0 valid precision: 0.11764705882352941\n",
      "Epoch 0 valid recall: 0.03225806451612903\n",
      "Epoch 0 valid f1: 0.05063291139240506\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.16it/s]\n",
      "1it [00:00,  3.26it/s]\n",
      " 40%|████      | 2/5 [00:02<00:03,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 train loss: 0.8514472842216492\n",
      "Epoch 1 valid loss: 0.9401633739471436\n",
      "Epoch 1 valid accuracy: 0.02631578947368421\n",
      "Epoch 1 valid precision: 0.125\n",
      "Epoch 1 valid recall: 0.03225806451612903\n",
      "Epoch 1 valid f1: 0.05128205128205128\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.19it/s]\n",
      "1it [00:00,  3.31it/s]\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 train loss: 0.7192738056182861\n",
      "Epoch 2 valid loss: 0.6289535760879517\n",
      "Epoch 2 valid accuracy: 0.043478260869565216\n",
      "Epoch 2 valid precision: 0.11764705882352941\n",
      "Epoch 2 valid recall: 0.06451612903225806\n",
      "Epoch 2 valid f1: 0.08333333333333333\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.17it/s]\n",
      "1it [00:00,  3.34it/s]\n",
      " 80%|████████  | 4/5 [00:04<00:01,  1.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 train loss: 0.435390442609787\n",
      "Epoch 3 valid loss: 0.7766780853271484\n",
      "Epoch 3 valid accuracy: 0.09482758620689655\n",
      "Epoch 3 valid precision: 0.16923076923076924\n",
      "Epoch 3 valid recall: 0.1774193548387097\n",
      "Epoch 3 valid f1: 0.1732283464566929\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [00:00,  1.17it/s]\n",
      "1it [00:00,  3.21it/s]\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 train loss: 0.40000200271606445\n",
      "Epoch 4 valid loss: 0.7848633527755737\n",
      "Epoch 4 valid accuracy: 0.0859375\n",
      "Epoch 4 valid precision: 0.14285714285714285\n",
      "Epoch 4 valid recall: 0.1774193548387097\n",
      "Epoch 4 valid f1: 0.15827338129496404\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train(ten_loader, valid_loader, vocab_size, epochs=5, lr=0.005, log=False, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 6,  0, 14,  8,  0,  0,  0,  2,  6,  8])\n"
     ]
    }
   ],
   "source": [
    "x, y = next(iter(ten_loader))\n",
    "y_hat = model(x)\n",
    "print(y.argmax(dim=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 1., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 1., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 1., 1., 0., 1., 1., 0., 0., 0., 1., 0., 0., 0., 0., 0., 1., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 0., 0., 0., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 1.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.where(torch.sigmoid(y_hat) > 0.2, torch.ones(y_hat.shape), torch.zeros(y_hat.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit 2 batches of data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "two_batches_loader = create_subset_dataloader(train_dataloader, num_samples=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:wvtc957l) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>▁▂▁▂▂▂▂▂▁▁▁▂▂▂▂▂█▃▂▂▂▂▂▂▂▁▁▁▁▁▂▂▁▁▁▁▁▂▂▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.42043</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">crimson-valley-16</strong> at: <a href='https://wandb.ai/hangjoni/bd4h-project/runs/wvtc957l' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project/runs/wvtc957l</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231122_171002-wvtc957l/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:wvtc957l). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/wandb/run-20231122_184729-pztjtyvc</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hangjoni/bd4h-project/runs/pztjtyvc' target=\"_blank\">stellar-terrain-17</a></strong> to <a href='https://wandb.ai/hangjoni/bd4h-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hangjoni/bd4h-project' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hangjoni/bd4h-project/runs/pztjtyvc' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project/runs/pztjtyvc</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:11<18:33, 11.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.6893196403980255\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 2/100 [00:21<16:57, 10.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 0.5394605845212936\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 3/100 [00:30<15:56,  9.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 loss 0.4229678809642792\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 4/100 [00:37<14:05,  8.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 loss 0.3586670905351639\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 5/100 [00:44<12:57,  8.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 loss 0.31571295857429504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 6/100 [00:51<12:11,  7.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 5 loss 0.2897985577583313\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 7/100 [01:00<12:39,  8.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 6 loss 0.26861102879047394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 8/100 [01:10<13:25,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 7 loss 0.2534335255622864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 9/100 [01:18<12:48,  8.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 8 loss 0.24157759547233582\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 10/100 [01:26<12:32,  8.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 9 loss 0.22888939082622528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 11/100 [01:33<11:42,  7.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 10 loss 0.2215374931693077\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 12/100 [01:39<10:59,  7.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 11 loss 0.2130671963095665\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 13/100 [01:49<11:50,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 12 loss 0.20530206710100174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 14%|█▍        | 14/100 [01:59<12:30,  8.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 13 loss 0.206512913107872\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 15/100 [02:07<12:07,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 14 loss 0.20684615522623062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 16/100 [02:15<11:27,  8.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 15 loss 0.20085904002189636\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 17/100 [02:22<11:06,  8.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 16 loss 0.19995411485433578\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 18/100 [02:30<10:53,  7.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 17 loss 0.20205532014369965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 19/100 [02:40<11:33,  8.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 18 loss 0.19636888056993484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 20/100 [02:47<10:49,  8.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 19 loss 0.1864580661058426\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 21/100 [02:57<11:21,  8.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 20 loss 0.1801273375749588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 22/100 [03:08<12:11,  9.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 loss 0.18123611062765121\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 23/100 [03:19<12:28,  9.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 22 loss 0.1774047240614891\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 24/100 [03:26<11:32,  9.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 23 loss 0.16386164724826813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 25/100 [03:35<11:19,  9.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 24 loss 0.16001787036657333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 26/100 [03:43<10:36,  8.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 25 loss 0.1528056636452675\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 27/100 [03:49<09:45,  8.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 26 loss 0.14428751170635223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 28/100 [03:56<09:07,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 27 loss 0.13980965316295624\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 29%|██▉       | 29/100 [04:05<09:28,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 28 loss 0.13516875356435776\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 30/100 [04:13<09:14,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 29 loss 0.13543881103396416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 31/100 [04:20<08:58,  7.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 30 loss 0.1335744671523571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 32/100 [04:28<08:44,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 31 loss 0.1314801201224327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 33/100 [04:37<09:00,  8.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 32 loss 0.13116095960140228\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 34/100 [04:43<08:26,  7.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 33 loss 0.14098674803972244\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 35%|███▌      | 35/100 [04:50<08:00,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 34 loss 0.15085270255804062\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 36/100 [04:57<07:36,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 35 loss 0.15590766072273254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 37/100 [05:04<07:41,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 36 loss 0.1643742471933365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 38/100 [05:11<07:22,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 37 loss 0.1507372260093689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 39%|███▉      | 39/100 [05:21<08:04,  7.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 38 loss 0.14343036711215973\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 40/100 [05:28<07:33,  7.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 39 loss 0.1384417936205864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 41/100 [05:36<07:48,  7.94s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 40 loss 0.13463637605309486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 42/100 [05:44<07:29,  7.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 41 loss 0.13242574408650398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 43/100 [05:52<07:27,  7.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 42 loss 0.13204479590058327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 44/100 [05:59<07:00,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43 loss 0.13157068192958832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 45%|████▌     | 45/100 [06:09<07:33,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 44 loss 0.13104566931724548\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 46/100 [06:18<07:47,  8.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 45 loss 0.13041288033127785\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 47/100 [06:25<07:08,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 46 loss 0.12993425503373146\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 48/100 [06:32<06:45,  7.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 47 loss 0.1293630227446556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 49/100 [06:39<06:18,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 48 loss 0.12877492606639862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 50/100 [06:45<05:57,  7.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 49 loss 0.1282314620912075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 51/100 [06:51<05:38,  6.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 50 loss 0.1277257800102234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 52/100 [06:58<05:26,  6.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 51 loss 0.12698376178741455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 53/100 [07:04<05:14,  6.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 52 loss 0.1263667233288288\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 54/100 [07:11<05:04,  6.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 53 loss 0.12590481713414192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 55/100 [07:17<04:54,  6.55s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 54 loss 0.12550506368279457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 56/100 [07:26<05:13,  7.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 55 loss 0.12513266876339912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 57/100 [07:33<05:13,  7.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 56 loss 0.1248079165816307\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 58/100 [07:40<04:54,  7.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 57 loss 0.12444084882736206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 59/100 [07:46<04:39,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 58 loss 0.12409771233797073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 60/100 [07:53<04:32,  6.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 59 loss 0.12373586371541023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 61/100 [08:02<04:51,  7.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 60 loss 0.12335054203867912\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 62/100 [08:09<04:42,  7.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 61 loss 0.1229386068880558\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 63/100 [08:17<04:41,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 62 loss 0.12250563502311707\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 64/100 [08:24<04:22,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 63 loss 0.12210097536444664\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▌   | 65/100 [08:32<04:27,  7.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 64 loss 0.12174494192004204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▌   | 66/100 [08:42<04:36,  8.14s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 65 loss 0.12149905413389206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 67/100 [08:51<04:39,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 66 loss 0.12127004936337471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 68/100 [08:58<04:21,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 67 loss 0.12104660272598267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 69/100 [09:06<04:05,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 68 loss 0.12081402912735939\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 70/100 [09:12<03:43,  7.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 69 loss 0.12057529762387276\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 71%|███████   | 71/100 [09:19<03:27,  7.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 70 loss 0.1203366369009018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 72/100 [09:27<03:32,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 71 loss 0.12009390816092491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 73/100 [09:34<03:15,  7.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 72 loss 0.1198529377579689\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 74/100 [09:40<03:01,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 73 loss 0.11963000148534775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 75/100 [09:49<03:10,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 74 loss 0.11942493915557861\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 76/100 [09:58<03:14,  8.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 75 loss 0.11921478062868118\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 77/100 [10:06<03:04,  8.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 76 loss 0.11899644881486893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 78/100 [10:12<02:45,  7.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 77 loss 0.11875937506556511\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 79/100 [10:19<02:30,  7.19s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 78 loss 0.11850178614258766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 80/100 [10:28<02:35,  7.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 79 loss 0.11824177205562592\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 81%|████████  | 81/100 [10:37<02:34,  8.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 80 loss 0.11804034188389778\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 82/100 [10:43<02:17,  7.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 81 loss 0.11784709990024567\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 83/100 [10:50<02:03,  7.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 82 loss 0.117656409740448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▍ | 84/100 [10:59<02:06,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 83 loss 0.11746703833341599\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 85/100 [11:07<01:56,  7.76s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 84 loss 0.117281474173069\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 86%|████████▌ | 86/100 [11:16<01:56,  8.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 85 loss 0.11709403246641159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 87/100 [11:26<01:53,  8.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 86 loss 0.11690415814518929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 88/100 [11:36<01:47,  8.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 87 loss 0.11671089753508568\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 89/100 [11:45<01:40,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 88 loss 0.11651740223169327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 90/100 [11:54<01:29,  9.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 89 loss 0.11632440984249115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 91/100 [12:01<01:16,  8.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 90 loss 0.11613336205482483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 92/100 [12:08<01:05,  8.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 91 loss 0.11594498157501221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 93/100 [12:15<00:53,  7.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 92 loss 0.11575526744127274\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 94/100 [12:22<00:45,  7.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 93 loss 0.115562304854393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 95/100 [12:30<00:37,  7.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 94 loss 0.11536028236150742\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 96%|█████████▌| 96/100 [12:37<00:30,  7.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 95 loss 0.11515707895159721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 97/100 [12:45<00:22,  7.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 96 loss 0.11494201421737671\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 98/100 [12:54<00:16,  8.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 97 loss 0.11468945443630219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 99/100 [13:01<00:07,  7.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98 loss 0.1144183985888958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [13:07<00:00,  7.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 99 loss 0.11418961361050606\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train(two_batches_loader, vocab_size, epochs=100, lr=0.005, log=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overfit to step 600"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "when training with full data, loss seems to blow up at the end of an epoch, near step 250. Let's triple the data size and see if the same happen to smaller dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import create_subset_dataloader\n",
    "dataloader = create_subset_dataloader(train_dataloader, num_samples=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:nuqej788) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">ethereal-smoke-2</strong> at: <a href='https://wandb.ai/hangjoni/bd4h-project-v1/runs/nuqej788' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project-v1/runs/nuqej788</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231122_200115-nuqej788/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:nuqej788). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/wandb/run-20231122_200149-eodj7xq3</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hangjoni/bd4h-project-v1/runs/eodj7xq3' target=\"_blank\">daily-wave-3</a></strong> to <a href='https://wandb.ai/hangjoni/bd4h-project-v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hangjoni/bd4h-project-v1' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project-v1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hangjoni/bd4h-project-v1/runs/eodj7xq3' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project-v1/runs/eodj7xq3</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [00:12,  6.21s/it] [00:00<?, ?it/s]\n",
      "2it [00:10,  5.44s/it] [00:12<1:01:54, 12.42s/it]\n",
      "2it [00:09,  4.79s/it] [00:23<57:11, 11.52s/it]  \n",
      "2it [00:09,  4.97s/it] [00:32<52:39, 10.64s/it]\n",
      "2it [00:09,  4.75s/it] [00:42<51:06, 10.36s/it]\n",
      "2it [00:09,  4.81s/it] [00:52<49:25, 10.05s/it]\n",
      "2it [00:10,  5.34s/it] [01:01<48:33,  9.91s/it]\n",
      "2it [00:09,  4.77s/it] [01:12<49:38, 10.16s/it]\n",
      "2it [00:09,  4.58s/it] [01:22<48:29,  9.97s/it]\n",
      "2it [00:09,  4.67s/it] [01:31<47:06,  9.71s/it]\n",
      "2it [00:11,  5.52s/it]0 [01:40<46:24,  9.60s/it]\n",
      "2it [00:09,  4.67s/it]0 [01:51<48:22, 10.04s/it]\n",
      "2it [00:09,  4.86s/it]0 [02:01<47:11,  9.83s/it]\n",
      "2it [00:09,  4.81s/it]0 [02:10<46:52,  9.80s/it]\n",
      "2it [00:10,  5.31s/it]0 [02:20<46:27,  9.75s/it]\n",
      "2it [00:09,  4.67s/it]0 [02:31<47:33, 10.01s/it]\n",
      "2it [00:08,  4.03s/it]0 [02:40<46:26,  9.81s/it]\n",
      "2it [00:06,  3.40s/it]0 [02:48<43:48,  9.29s/it]\n",
      "2it [00:08,  4.10s/it]0 [02:55<40:07,  8.54s/it]\n",
      "2it [00:08,  4.18s/it]0 [03:03<39:31,  8.44s/it]\n",
      "2it [00:06,  3.42s/it]0 [03:11<39:15,  8.41s/it]\n",
      "2it [00:06,  3.41s/it]0 [03:18<36:55,  7.94s/it]\n",
      "2it [00:09,  4.78s/it]0 [03:25<35:14,  7.61s/it]\n",
      "2it [00:07,  3.87s/it]0 [03:35<37:50,  8.20s/it]\n",
      "2it [00:09,  4.87s/it]0 [03:42<37:04,  8.06s/it]\n",
      "2it [00:09,  4.75s/it]0 [03:52<39:15,  8.57s/it]\n",
      "2it [00:09,  4.70s/it]0 [04:02<40:24,  8.85s/it]\n",
      "2it [00:09,  4.87s/it]0 [04:11<41:01,  9.02s/it]\n",
      "2it [00:09,  4.85s/it]0 [04:21<41:51,  9.23s/it]\n",
      "2it [00:08,  4.18s/it]0 [04:30<42:21,  9.38s/it]\n",
      "2it [00:08,  4.40s/it]0 [04:39<40:49,  9.07s/it]\n",
      "2it [00:07,  3.66s/it]0 [04:48<40:19,  8.99s/it]\n",
      "2it [00:09,  4.63s/it]0 [04:55<37:56,  8.49s/it]\n",
      "2it [00:07,  3.81s/it]0 [05:04<38:48,  8.72s/it]\n",
      "2it [00:06,  3.31s/it]0 [05:12<37:12,  8.39s/it]\n",
      "2it [00:06,  3.36s/it]0 [05:18<34:43,  7.86s/it]\n",
      "2it [00:06,  3.35s/it]0 [05:25<33:04,  7.52s/it]\n",
      "2it [00:07,  3.74s/it]0 [05:32<31:52,  7.27s/it]\n",
      "2it [00:06,  3.46s/it]0 [05:39<32:02,  7.34s/it]\n",
      "2it [00:06,  3.41s/it]0 [05:46<31:22,  7.21s/it]\n",
      "2it [00:06,  3.50s/it]0 [05:53<30:45,  7.10s/it]\n",
      "2it [00:09,  4.78s/it]0 [06:00<30:30,  7.07s/it]\n",
      "2it [00:06,  3.39s/it]0 [06:10<33:35,  7.81s/it]\n",
      "2it [00:08,  4.31s/it]0 [06:16<32:07,  7.50s/it]\n",
      "2it [00:08,  4.34s/it]0 [06:25<33:26,  7.84s/it]\n",
      "2it [00:07,  3.64s/it]0 [06:34<34:23,  8.09s/it]\n",
      "2it [00:09,  4.80s/it]0 [06:41<33:14,  7.85s/it]\n",
      "2it [00:07,  3.82s/it]0 [06:51<35:19,  8.38s/it]\n",
      "2it [00:09,  4.69s/it]0 [06:58<34:15,  8.16s/it]\n",
      "2it [00:07,  3.81s/it]0 [07:08<35:39,  8.52s/it]\n",
      "2it [00:06,  3.27s/it]0 [07:15<34:23,  8.25s/it]\n",
      "2it [00:06,  3.35s/it]0 [07:22<32:07,  7.74s/it]\n",
      "2it [00:06,  3.36s/it]0 [07:29<30:42,  7.43s/it]\n",
      "2it [00:06,  3.38s/it]0 [07:35<29:42,  7.22s/it]\n",
      "2it [00:09,  4.53s/it]0 [07:42<29:01,  7.08s/it]\n",
      "2it [00:07,  3.91s/it]0 [07:51<31:20,  7.68s/it]\n",
      "2it [00:08,  4.26s/it]0 [07:59<31:23,  7.72s/it]\n",
      "2it [00:08,  4.07s/it]0 [08:07<32:15,  7.96s/it]\n",
      "2it [00:06,  3.38s/it]0 [08:16<32:19,  8.02s/it]\n",
      "2it [00:06,  3.37s/it]0 [08:22<30:40,  7.64s/it]\n",
      "2it [00:06,  3.45s/it]0 [08:29<29:28,  7.37s/it]\n",
      "2it [00:09,  4.96s/it]0 [08:36<28:48,  7.23s/it]\n",
      "2it [00:07,  3.97s/it]0 [08:46<31:53,  8.04s/it]\n",
      "2it [00:06,  3.34s/it]0 [08:54<31:38,  8.01s/it]\n",
      "2it [00:09,  4.91s/it]0 [09:01<29:57,  7.62s/it]\n",
      "2it [00:09,  4.51s/it]0 [09:10<32:25,  8.28s/it]\n",
      "2it [00:09,  4.82s/it]0 [09:19<33:08,  8.50s/it]\n",
      "2it [00:09,  4.71s/it]0 [09:29<34:20,  8.84s/it]\n",
      "2it [00:09,  5.00s/it]0 [09:38<34:52,  9.02s/it]\n",
      "2it [00:10,  5.18s/it]0 [09:48<35:51,  9.31s/it]\n",
      "2it [00:09,  4.91s/it]0 [09:59<36:54,  9.63s/it]\n",
      "2it [00:09,  4.55s/it]0 [10:09<36:58,  9.69s/it]\n",
      "2it [00:07,  3.89s/it]0 [10:18<36:09,  9.51s/it]\n",
      "2it [00:07,  3.84s/it]0 [10:26<34:02,  9.00s/it]\n",
      "2it [00:07,  3.88s/it]0 [10:33<32:24,  8.60s/it]\n",
      "2it [00:06,  3.41s/it]0 [10:41<31:18,  8.35s/it]\n",
      "2it [00:06,  3.35s/it]0 [10:48<29:27,  7.89s/it]\n",
      "2it [00:07,  3.94s/it]0 [10:55<27:59,  7.53s/it]\n",
      "2it [00:09,  4.84s/it]0 [11:02<28:15,  7.64s/it]\n",
      "2it [00:08,  4.02s/it]0 [11:12<30:24,  8.25s/it]\n",
      "2it [00:06,  3.36s/it]0 [11:20<30:01,  8.19s/it]\n",
      "2it [00:06,  3.41s/it]0 [11:27<28:16,  7.75s/it]\n",
      "2it [00:06,  3.45s/it]0 [11:34<27:08,  7.47s/it]\n",
      "2it [00:09,  4.89s/it]0 [11:41<26:23,  7.30s/it]\n",
      "2it [00:07,  3.96s/it]0 [11:50<28:56,  8.04s/it]\n",
      "2it [00:07,  3.99s/it]0 [11:58<28:40,  8.00s/it]\n",
      "2it [00:08,  4.31s/it]0 [12:06<28:30,  7.99s/it]\n",
      "2it [00:08,  4.49s/it]0 [12:15<29:02,  8.18s/it]\n",
      "2it [00:09,  4.80s/it]0 [12:24<29:45,  8.42s/it]\n",
      "2it [00:09,  4.87s/it]0 [12:33<30:52,  8.78s/it]\n",
      "2it [00:09,  4.86s/it]0 [12:43<31:44,  9.07s/it]\n",
      "2it [00:09,  4.70s/it]0 [12:53<32:17,  9.27s/it]\n",
      "2it [00:07,  3.84s/it]0 [13:02<32:16,  9.31s/it]\n",
      "2it [00:07,  3.78s/it]0 [13:10<30:26,  8.82s/it]\n",
      "2it [00:07,  3.80s/it]0 [13:18<28:59,  8.44s/it]\n",
      "2it [00:06,  3.38s/it]0 [13:25<27:58,  8.19s/it]\n",
      "2it [00:06,  3.14s/it]0 [13:32<26:23,  7.76s/it]\n",
      "2it [00:06,  3.20s/it]0 [13:38<24:45,  7.32s/it]\n",
      "2it [00:07,  3.70s/it]0 [13:45<23:42,  7.04s/it]\n",
      "2it [00:06,  3.13s/it]0 [13:52<23:57,  7.15s/it]\n",
      "2it [00:06,  3.14s/it]00 [13:58<22:57,  6.89s/it]\n",
      "2it [00:06,  3.43s/it]00 [14:05<22:14,  6.71s/it]\n",
      "2it [00:08,  4.28s/it]00 [14:11<22:17,  6.76s/it]\n",
      "2it [00:07,  3.56s/it]00 [14:20<23:57,  7.30s/it]\n",
      "2it [00:07,  3.54s/it]00 [14:27<23:40,  7.25s/it]\n",
      "2it [00:05,  2.95s/it]00 [14:34<23:23,  7.20s/it]\n",
      "2it [00:06,  3.11s/it]00 [14:40<22:00,  6.81s/it]\n",
      "2it [00:06,  3.14s/it]00 [14:46<21:19,  6.63s/it]\n",
      "2it [00:08,  4.00s/it]00 [14:53<20:53,  6.53s/it]\n",
      "2it [00:07,  3.60s/it]00 [15:01<22:11,  6.97s/it]\n",
      "2it [00:07,  3.60s/it]00 [15:08<22:18,  7.04s/it]\n",
      "2it [00:06,  3.13s/it]00 [15:15<22:19,  7.09s/it]\n",
      "2it [00:06,  3.32s/it]00 [15:21<21:26,  6.84s/it]\n",
      "2it [00:06,  3.16s/it]00 [15:28<21:08,  6.78s/it]\n",
      "2it [00:06,  3.36s/it]00 [15:34<20:36,  6.65s/it]\n",
      "2it [00:06,  3.23s/it]00 [15:41<20:34,  6.67s/it]\n",
      "2it [00:06,  3.28s/it]00 [15:47<20:16,  6.61s/it]\n",
      "2it [00:07,  3.92s/it]00 [15:54<20:07,  6.60s/it]\n",
      "2it [00:07,  3.93s/it]00 [16:02<21:08,  6.97s/it]\n",
      "2it [00:06,  3.39s/it]00 [16:10<21:50,  7.24s/it]\n",
      "2it [00:06,  3.14s/it]00 [16:17<21:18,  7.10s/it]\n",
      "2it [00:06,  3.16s/it]00 [16:23<20:27,  6.85s/it]\n",
      "2it [00:06,  3.16s/it]00 [16:29<19:51,  6.70s/it]\n",
      "2it [00:06,  3.18s/it]00 [16:35<19:25,  6.59s/it]\n",
      "2it [00:06,  3.14s/it]00 [16:42<19:07,  6.52s/it]\n",
      "2it [00:06,  3.45s/it]00 [16:48<18:48,  6.45s/it]\n",
      "2it [00:06,  3.20s/it]00 [16:55<19:05,  6.58s/it]\n",
      "2it [00:06,  3.21s/it]00 [17:01<18:50,  6.53s/it]\n",
      "2it [00:07,  3.86s/it]00 [17:08<18:38,  6.50s/it]\n",
      "2it [00:06,  3.38s/it]00 [17:16<19:34,  6.87s/it]\n",
      "2it [00:06,  3.34s/it]00 [17:22<19:22,  6.84s/it]\n",
      "2it [00:06,  3.27s/it]00 [17:29<19:07,  6.79s/it]\n",
      "2it [00:06,  3.41s/it]00 [17:36<18:48,  6.72s/it]\n",
      "2it [00:08,  4.01s/it]00 [17:42<18:47,  6.75s/it]\n",
      "2it [00:08,  4.33s/it]00 [17:50<19:43,  7.13s/it]\n",
      "2it [00:07,  3.59s/it]00 [17:59<20:52,  7.59s/it]\n",
      "2it [00:07,  3.66s/it]00 [18:06<20:24,  7.47s/it]\n",
      "2it [00:06,  3.15s/it]00 [18:14<20:09,  7.42s/it]\n",
      "2it [00:07,  3.63s/it]00 [18:20<19:07,  7.09s/it]\n",
      "2it [00:07,  3.85s/it]00 [18:27<19:09,  7.14s/it]\n",
      "2it [00:07,  3.70s/it]00 [18:35<19:29,  7.31s/it]\n",
      "2it [00:06,  3.12s/it]00 [18:42<19:26,  7.34s/it]\n",
      "2it [00:06,  3.10s/it]00 [18:48<18:27,  7.01s/it]\n",
      "2it [00:06,  3.17s/it]00 [18:55<17:42,  6.77s/it]\n",
      "2it [00:06,  3.23s/it]00 [19:01<17:15,  6.64s/it]\n",
      "2it [00:06,  3.16s/it]00 [19:07<17:01,  6.59s/it]\n",
      "2it [00:06,  3.27s/it]00 [19:14<16:41,  6.51s/it]\n",
      "2it [00:06,  3.19s/it]00 [19:20<16:36,  6.51s/it]\n",
      "2it [00:08,  4.03s/it]00 [19:27<16:24,  6.47s/it]\n",
      "2it [00:06,  3.15s/it]00 [19:35<17:29,  6.95s/it]\n",
      "2it [00:06,  3.12s/it]00 [19:41<16:52,  6.75s/it]\n",
      "2it [00:07,  3.96s/it]00 [19:47<16:23,  6.60s/it]\n",
      "2it [00:07,  3.60s/it]00 [19:55<17:15,  7.00s/it]\n",
      "2it [00:07,  3.54s/it]00 [20:02<17:17,  7.06s/it]\n",
      "2it [00:06,  3.16s/it]00 [20:10<17:11,  7.06s/it]\n",
      "2it [00:06,  3.11s/it]00 [20:16<16:32,  6.84s/it]\n",
      "2it [00:06,  3.16s/it]00 [20:22<15:58,  6.65s/it]\n",
      "2it [00:06,  3.18s/it]00 [20:28<15:37,  6.55s/it]\n",
      "2it [00:06,  3.17s/it]00 [20:35<15:22,  6.49s/it]\n",
      "2it [00:06,  3.17s/it]00 [20:41<15:09,  6.45s/it]\n",
      "2it [00:06,  3.16s/it]00 [20:47<14:58,  6.42s/it]\n",
      "2it [00:06,  3.11s/it]00 [20:54<14:47,  6.38s/it]\n",
      "2it [00:06,  3.27s/it]00 [21:00<14:34,  6.34s/it]\n",
      "2it [00:06,  3.15s/it]00 [21:06<14:36,  6.40s/it]\n",
      "2it [00:06,  3.17s/it]00 [21:13<14:26,  6.37s/it]\n",
      "2it [00:06,  3.14s/it]00 [21:19<14:18,  6.36s/it]\n",
      "2it [00:06,  3.14s/it]00 [21:25<14:08,  6.33s/it]\n",
      "2it [00:06,  3.37s/it]00 [21:32<13:59,  6.32s/it]\n",
      "2it [00:08,  4.34s/it]00 [21:38<14:10,  6.44s/it]\n",
      "2it [00:06,  3.09s/it]00 [21:47<15:31,  7.11s/it]\n",
      "2it [00:06,  3.25s/it]00 [21:53<14:48,  6.83s/it]\n",
      "2it [00:07,  3.87s/it]00 [22:00<14:28,  6.74s/it]\n",
      "2it [00:06,  3.37s/it]00 [22:08<15:00,  7.04s/it]\n",
      "2it [00:07,  3.88s/it]00 [22:14<14:42,  6.95s/it]\n",
      "2it [00:06,  3.26s/it]00 [22:22<15:05,  7.19s/it]\n",
      "2it [00:06,  3.20s/it]00 [22:29<14:33,  6.99s/it]\n",
      "2it [00:06,  3.21s/it]00 [22:35<14:04,  6.81s/it]\n",
      "2it [00:07,  3.94s/it]00 [22:41<13:43,  6.69s/it]\n",
      "2it [00:06,  3.25s/it]00 [22:49<14:19,  7.05s/it]\n",
      "2it [00:07,  3.71s/it]00 [22:56<13:52,  6.88s/it]\n",
      "2it [00:09,  4.62s/it]00 [23:03<14:05,  7.05s/it]\n",
      "2it [00:08,  4.35s/it]00 [23:12<15:16,  7.70s/it]\n",
      "2it [00:07,  3.63s/it]00 [23:21<15:44,  8.00s/it]\n",
      "2it [00:07,  3.67s/it]00 [23:28<15:10,  7.78s/it]\n",
      "2it [00:08,  4.45s/it]00 [23:36<14:46,  7.65s/it]\n",
      "2it [00:07,  3.60s/it]00 [23:45<15:22,  8.02s/it]\n",
      "2it [00:09,  4.57s/it]00 [23:52<14:46,  7.78s/it]\n",
      "2it [00:07,  3.81s/it]00 [24:01<15:24,  8.18s/it]\n",
      "2it [00:08,  4.38s/it]00 [24:09<14:57,  8.01s/it]\n",
      "2it [00:07,  3.69s/it]00 [24:17<15:14,  8.24s/it]\n",
      "2it [00:07,  3.61s/it]00 [24:25<14:37,  7.98s/it]\n",
      "2it [00:07,  3.59s/it]00 [24:32<14:05,  7.75s/it]\n",
      "2it [00:07,  3.62s/it]00 [24:39<13:39,  7.58s/it]\n",
      "2it [00:06,  3.14s/it]00 [24:46<13:20,  7.48s/it]\n",
      "2it [00:06,  3.10s/it]00 [24:53<12:34,  7.12s/it]\n",
      "2it [00:06,  3.19s/it]00 [24:59<11:58,  6.85s/it]\n",
      "2it [00:06,  3.18s/it]00 [25:05<11:37,  6.71s/it]\n",
      "2it [00:06,  3.19s/it]00 [25:12<11:20,  6.60s/it]\n",
      "2it [00:06,  3.27s/it]00 [25:18<11:06,  6.53s/it]\n",
      "2it [00:06,  3.19s/it]00 [25:24<11:00,  6.54s/it]\n",
      "2it [00:07,  3.77s/it]00 [25:31<10:49,  6.49s/it]\n",
      "2it [00:07,  3.97s/it]00 [25:38<11:13,  6.81s/it]\n",
      "2it [00:07,  3.75s/it]00 [25:46<11:40,  7.15s/it]\n",
      "2it [00:07,  3.59s/it]00 [25:54<11:43,  7.25s/it]\n",
      "2it [00:07,  3.61s/it]00 [26:01<11:34,  7.23s/it]\n",
      "2it [00:08,  4.02s/it]00 [26:08<11:26,  7.23s/it]\n",
      "2it [00:07,  3.81s/it]00 [26:16<11:42,  7.47s/it]\n",
      "2it [00:07,  3.57s/it]00 [26:24<11:38,  7.52s/it]\n",
      "2it [00:07,  3.53s/it]00 [26:31<11:21,  7.40s/it]\n",
      "2it [00:06,  3.09s/it]00 [26:38<11:04,  7.30s/it]\n",
      "2it [00:06,  3.16s/it]00 [26:44<10:27,  6.97s/it]\n",
      "2it [00:06,  3.17s/it]00 [26:51<10:02,  6.77s/it]\n",
      "2it [00:07,  3.88s/it]00 [26:57<09:44,  6.64s/it]\n",
      "2it [00:12,  6.03s/it]00 [27:05<10:07,  6.98s/it]\n",
      "2it [00:09,  4.57s/it]00 [27:17<12:11,  8.50s/it]\n",
      "2it [00:07,  3.87s/it]00 [27:26<12:19,  8.70s/it]\n",
      "2it [00:06,  3.34s/it]00 [27:34<11:46,  8.41s/it]\n",
      "2it [00:06,  3.21s/it]00 [27:40<10:55,  7.89s/it]\n",
      "2it [00:06,  3.20s/it]00 [27:47<10:10,  7.45s/it]\n",
      "2it [00:31, 15.76s/it]00 [27:53<09:38,  7.14s/it]\n",
      "2it [00:08,  4.36s/it]00 [28:25<19:16, 14.45s/it]\n",
      "2it [00:07,  3.61s/it]00 [28:33<16:45, 12.73s/it]\n",
      "2it [00:08,  4.47s/it]00 [28:41<14:24, 11.08s/it]\n",
      "2it [00:07,  3.69s/it]00 [28:50<13:23, 10.44s/it]\n",
      "2it [00:07,  3.60s/it]00 [28:57<12:03,  9.52s/it]\n",
      "2it [13:35, 407.75s/it]0 [29:04<11:01,  8.83s/it]\n",
      "2it [00:07,  3.62s/it]00 [42:40<5:09:21, 250.83s/it]\n",
      "2it [00:08,  4.44s/it]00 [42:47<3:36:15, 177.75s/it]\n",
      "2it [00:07,  3.96s/it]00 [42:56<2:32:30, 127.09s/it]\n",
      "2it [00:06,  3.34s/it]00 [43:04<1:48:05, 91.34s/it] \n",
      "2it [00:06,  3.19s/it]00 [43:10<1:16:55, 65.94s/it]\n",
      "2it [01:27, 43.98s/it]00 [43:17<55:17, 48.08s/it]  \n",
      "2it [00:08,  4.28s/it]00 [44:45<1:08:02, 60.04s/it]\n",
      "2it [00:07,  3.62s/it]00 [44:53<49:48, 44.60s/it]  \n",
      "2it [00:06,  3.42s/it]00 [45:01<36:43, 33.39s/it]\n",
      "2it [00:06,  3.20s/it]00 [45:07<27:32, 25.43s/it]\n",
      "2it [00:06,  3.14s/it]00 [45:14<21:01, 19.72s/it]\n",
      "2it [00:06,  3.15s/it]00 [45:20<16:28, 15.69s/it]\n",
      "2it [00:07,  3.97s/it]00 [45:26<13:18, 12.87s/it]\n",
      "2it [00:07,  3.64s/it]00 [45:34<11:35, 11.40s/it]\n",
      "2it [00:07,  3.53s/it]00 [45:42<10:09, 10.16s/it]\n",
      "2it [00:07,  3.76s/it]00 [45:49<09:04,  9.23s/it]\n",
      "2it [00:09,  4.64s/it]00 [45:56<08:25,  8.72s/it]\n",
      "2it [00:08,  4.19s/it]00 [46:05<08:26,  8.89s/it]\n",
      "2it [00:06,  3.46s/it]00 [46:14<08:09,  8.74s/it]\n",
      "2it [00:06,  3.22s/it]00 [46:21<07:30,  8.19s/it]\n",
      "2it [00:09,  4.91s/it]00 [46:27<06:54,  7.67s/it]\n",
      "2it [00:10,  5.21s/it]00 [46:37<07:20,  8.31s/it]\n",
      "2it [06:19, 189.70s/it]0 [46:47<07:45,  8.95s/it]\n",
      "2it [00:08,  4.46s/it]00 [53:07<1:42:04, 120.08s/it]\n",
      "2it [00:06,  3.10s/it]00 [53:16<1:12:16, 86.74s/it] \n",
      "2it [00:06,  3.18s/it]00 [53:22<51:06, 62.57s/it]  \n",
      "2it [00:07,  3.88s/it]00 [53:28<36:34, 45.71s/it]\n",
      "2it [00:07,  3.62s/it]00 [53:36<26:53, 34.33s/it]\n",
      "2it [00:06,  3.22s/it]00 [53:43<20:05, 26.20s/it]\n",
      "2it [00:06,  3.14s/it]00 [53:50<15:12, 20.27s/it]\n",
      "2it [00:06,  3.12s/it]00 [53:56<11:47, 16.07s/it]\n",
      "2it [00:06,  3.16s/it]00 [54:02<09:24, 13.12s/it]\n",
      "2it [00:06,  3.18s/it]00 [54:09<07:45, 11.08s/it]\n",
      "2it [00:06,  3.17s/it]00 [54:15<06:36,  9.67s/it]\n",
      "2it [00:07,  3.94s/it]00 [54:21<05:46,  8.67s/it]\n",
      "2it [00:07,  3.67s/it]00 [54:29<05:28,  8.43s/it]\n",
      "2it [00:07,  3.57s/it]00 [54:37<05:07,  8.10s/it]\n",
      "2it [00:06,  3.07s/it]00 [54:44<04:49,  7.82s/it]\n",
      "2it [00:07,  3.63s/it]00 [54:50<04:23,  7.31s/it]\n",
      "2it [00:06,  3.22s/it]00 [54:57<04:15,  7.30s/it]\n",
      "2it [00:10,  5.33s/it]00 [55:04<03:59,  7.04s/it]\n",
      "2it [00:12,  6.35s/it]00 [55:14<04:28,  8.13s/it]\n",
      "2it [05:05, 152.63s/it]0 [55:27<05:04,  9.50s/it]\n",
      "2it [00:07,  3.96s/it]00 [1:00:32<50:45, 98.23s/it]\n",
      "2it [00:07,  3.56s/it]00 [1:00:40<35:34, 71.14s/it]\n",
      "2it [00:07,  3.56s/it]00 [1:00:47<25:06, 51.93s/it]\n",
      "2it [00:07,  3.55s/it]00 [1:00:54<17:57, 38.49s/it]\n",
      "2it [00:07,  3.80s/it]00 [1:01:01<13:05, 29.07s/it]\n",
      "2it [00:07,  3.77s/it]00 [1:01:09<09:48, 22.63s/it]\n",
      "2it [10:11, 305.70s/it]0 [1:01:17<07:32, 18.10s/it]\n",
      "2it [00:07,  3.60s/it]00 [1:11:28<1:18:26, 196.09s/it]\n",
      "2it [00:06,  3.08s/it]00 [1:11:35<53:26, 139.43s/it]  \n",
      "2it [00:06,  3.16s/it]00 [1:11:41<36:27, 99.45s/it] \n",
      "2it [00:06,  3.13s/it]00 [1:11:48<25:01, 71.51s/it]\n",
      "2it [00:06,  3.15s/it]00 [1:11:54<17:18, 51.94s/it]\n",
      "2it [00:06,  3.13s/it]00 [1:12:00<12:06, 38.25s/it]\n",
      "2it [00:06,  3.11s/it]00 [1:12:07<08:35, 28.65s/it]\n",
      "2it [00:06,  3.36s/it]00 [1:12:13<06:12, 21.92s/it]\n",
      "2it [00:08,  4.30s/it]00 [1:12:19<04:37, 17.36s/it]\n",
      "2it [00:07,  3.57s/it]00 [1:12:28<03:41, 14.74s/it]\n",
      "2it [00:05,  2.96s/it]00 [1:12:35<02:54, 12.46s/it]\n",
      "2it [00:06,  3.41s/it]00 [1:12:41<02:16, 10.50s/it]\n",
      "2it [00:06,  3.18s/it]00 [1:12:48<01:52,  9.39s/it]\n",
      "2it [00:06,  3.22s/it]00 [1:12:54<01:33,  8.48s/it]\n",
      "2it [00:09,  4.51s/it]00 [1:13:01<01:18,  7.87s/it]\n",
      "2it [00:07,  3.76s/it]00 [1:13:10<01:13,  8.22s/it]\n",
      "2it [00:06,  3.38s/it]00 [1:13:17<01:04,  8.01s/it]\n",
      "2it [00:06,  3.38s/it]00 [1:13:24<00:53,  7.64s/it]\n",
      "2it [00:08,  4.49s/it]00 [1:13:31<00:44,  7.37s/it]\n",
      "2it [00:07,  3.63s/it]00 [1:13:40<00:39,  7.85s/it]\n",
      "2it [00:07,  3.58s/it]00 [1:13:47<00:30,  7.67s/it]\n",
      "2it [00:07,  3.79s/it]00 [1:13:54<00:22,  7.52s/it]\n",
      "2it [00:11,  5.84s/it]00 [1:14:02<00:15,  7.54s/it]\n",
      "2it [00:11,  5.97s/it]00 [1:14:13<00:08,  8.78s/it]\n",
      "100%|██████████| 300/300 [1:14:25<00:00, 14.89s/it]\n"
     ]
    }
   ],
   "source": [
    "model = train(dataloader, vocab_size, epochs=300, lr=0.005, log=True, verbose=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all look good. weird that full data training has loss going up. Trying again with shuffled data and high lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train for real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import wandb\n",
    "\n",
    "# import constants\n",
    "from constants import *\n",
    "\n",
    "# Add the parent directory to the system path\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from HLAN.data_util_gensim import create_vocabulary_label_pre_split, create_vocabulary\n",
    "from utils import load_data_multilabel_pre_split , create_dataloaders, initialization_using_word2vec\n",
    "from HAN_model import HierarchicalAttentionNetwork\n",
    "\n",
    "from metrics import *\n",
    "\n",
    "\n",
    "def train(dataloader, vocab_size, epochs=1, lr=0.0005, log=True, project=\"bd4h-project\"):\n",
    "    model = HierarchicalAttentionNetwork(vocab_size=vocab_size, embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, num_sentences=NUM_SENTENCES, sentence_length=SENTENCE_LENGTH, num_classes=NUM_CLASSES)\n",
    "    model = initialization_using_word2vec(model)\n",
    "    criterion = nn.BCEWithLogitsLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=3)\n",
    "\n",
    "    if log:\n",
    "        wandb.init(\n",
    "            # set the wandb project where this run will be logged\n",
    "            project=project,\n",
    "            \n",
    "            # track hyperparameters and run metadata\n",
    "            config={\n",
    "            \"learning_rate\": lr,\n",
    "            \"architecture\": \"HLAN+LE\",\n",
    "            \"dataset\": \"mimic-50\",\n",
    "            \"epochs\": epochs,\n",
    "            \"loss\": \"BCEWithLogitsLoss\"\n",
    "            }\n",
    "        )\n",
    "        wandb.watch(model, criterion, log='all', log_freq=1)\n",
    "\n",
    "    logger = SummaryWriter(\"./logs/\")\n",
    "\n",
    "    for epoch in tqdm(range(epochs)):\n",
    "        losses = []\n",
    "        for x, y in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            y_hat = model(x)\n",
    "            loss = criterion(y_hat, y)\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "            optimizer.step()\n",
    "            \n",
    "            if log:\n",
    "                wandb.log({'loss': loss.item()})\n",
    "                for layer, (tag, value) in enumerate(model.named_parameters()):\n",
    "                    logger.add_histogram(f\"grad/{layer}.{tag}\", value.grad.cpu(), i)\n",
    "            \n",
    "        print('epoch', epoch, 'loss', np.array(losses).mean())\n",
    "        scheduler.step(np.array(losses).mean())\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:8epc6f6w) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▆▅▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.03946</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">stoic-durian-14</strong> at: <a href='https://wandb.ai/hangjoni/bd4h-project/runs/8epc6f6w' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project/runs/8epc6f6w</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231122_145629-8epc6f6w/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:8epc6f6w). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/wandb/run-20231122_151319-z5jbd9lu</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hangjoni/bd4h-project-v1/runs/z5jbd9lu' target=\"_blank\">lucky-salad-1</a></strong> to <a href='https://wandb.ai/hangjoni/bd4h-project-v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hangjoni/bd4h-project-v1' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project-v1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hangjoni/bd4h-project-v1/runs/z5jbd9lu' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project-v1/runs/z5jbd9lu</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [13:39<54:37, 819.47s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.38444908982209064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [26:26<39:25, 788.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 0.39879510902133386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [40:23<27:01, 810.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 loss 0.3494505654917404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [53:56<13:31, 811.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 loss 0.34063784954811743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [1:07:04<00:00, 804.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 loss 0.3346067282404353\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train(train_dataloader, vocab_size, epochs=5, lr=0.00005, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(new_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1., 0., 1., 0., 0., 1., 1., 1., 1., 0., 1., 1., 1., 0., 1.,\n",
       "         1., 1., 0., 1., 1., 0., 1., 0., 1., 0., 0., 0., 1., 1., 0., 0., 1., 0.,\n",
       "         0., 0., 0., 0., 0., 1., 0., 0., 0., 1., 0., 1., 0., 0.]])"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = model(x)\n",
    "torch.where(torch.sigmoid(y_hat) > 0.1, torch.ones(y_hat.shape), torch.zeros(y_hat.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[41, 43, 22,  ...,  0,  0,  0]])"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x[0,-30:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### train with higher initial learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:si471n8e) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▄▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.05901</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">copper-glitter-15</strong> at: <a href='https://wandb.ai/hangjoni/bd4h-project/runs/si471n8e' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project/runs/si471n8e</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231122_165253-si471n8e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:si471n8e). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/wandb/run-20231122_171002-wvtc957l</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hangjoni/bd4h-project/runs/wvtc957l' target=\"_blank\">crimson-valley-16</a></strong> to <a href='https://wandb.ai/hangjoni/bd4h-project' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hangjoni/bd4h-project' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hangjoni/bd4h-project/runs/wvtc957l' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project/runs/wvtc957l</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 1/5 [13:35<54:23, 815.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0 loss 0.3926349367077643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 2/5 [27:03<40:33, 811.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 loss 0.38670202512514923\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 3/5 [40:58<27:23, 821.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 2 loss 0.4673087099795285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 4/5 [55:09<13:53, 833.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 3 loss 0.3527893528283349\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [1:09:44<00:00, 836.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 4 loss 0.34148601904923737\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "model = train(train_dataloader, vocab_size, epochs=5, lr=0.005, log=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train full data 20 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cache_path: ../cache_vocabulary_label_pik/mimic3-ds-50-HAN_word_vocabulary.pik file_exists: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:eodj7xq3) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Source type is set to 'repo' but some required information is missing from the environment. A job will not be created from this run. See https://docs.wandb.ai/guides/launch/create-job\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: left ; width: auto;} td:nth-child(2) {text-align: left ; width: 100%}\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; justify-content: flex-start; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>█▅▄▃▂▂▃▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>loss</td><td>0.00617</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">daily-wave-3</strong> at: <a href='https://wandb.ai/hangjoni/bd4h-project-v1/runs/eodj7xq3' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project-v1/runs/eodj7xq3</a><br/>Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20231122_200149-eodj7xq3/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:eodj7xq3). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/hungryfoolish/Documents/OMSCS/BD4H/project/Explainable-Automated-Medical-Coding-master/HLAN_pytorch/wandb/run-20231123_065321-lp3lwwya</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hangjoni/bd4h-project-v1/runs/lp3lwwya' target=\"_blank\">restful-music-4</a></strong> to <a href='https://wandb.ai/hangjoni/bd4h-project-v1' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hangjoni/bd4h-project-v1' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project-v1</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hangjoni/bd4h-project-v1/runs/lp3lwwya' target=\"_blank\">https://wandb.ai/hangjoni/bd4h-project-v1/runs/lp3lwwya</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "253it [50:00, 11.86s/it]0:00<?, ?it/s]\n",
      "253it [1:03:29, 15.06s/it]00<15:50:04, 3000.24s/it]\n",
      "253it [1:10:56, 16.83s/it]3:29<17:22:50, 3476.12s/it]\n",
      "253it [16:57,  4.02s/it]:04:26<18:05:54, 3832.62s/it]\n",
      "253it [19:17,  4.57s/it]:21:24<12:05:42, 2721.41s/it]\n",
      "253it [19:14,  4.56s/it]:40:41<8:59:20, 2157.37s/it] \n",
      "253it [21:49,  5.17s/it]:59:56<7:03:50, 1816.45s/it]\n",
      "253it [1:21:40, 19.37s/it]1:45<5:57:38, 1650.64s/it]\n",
      "253it [1:23:24, 19.78s/it]3:25<8:57:01, 2685.13s/it]\n",
      "253it [56:57, 13.51s/it]:06:49<10:25:11, 3410.13s/it]\n",
      "253it [35:01,  8.30s/it]8:03:47<9:28:43, 3412.40s/it]\n",
      "253it [14:21,  3.41s/it]8:38:48<7:31:39, 3011.05s/it]\n",
      "253it [15:58,  3.79s/it]8:53:10<5:14:17, 2357.23s/it]\n",
      "253it [15:04,  3.57s/it]9:09:08<3:45:35, 1933.59s/it]\n",
      "253it [15:30,  3.68s/it]9:24:13<2:42:15, 1622.66s/it]\n",
      "253it [15:14,  3.61s/it]9:39:43<1:57:49, 1413.88s/it]\n",
      "253it [18:51,  4.47s/it]9:54:57<1:24:13, 1263.47s/it]\n",
      "253it [14:41,  3.48s/it]10:13:48<1:01:11, 1223.74s/it]\n",
      "253it [15:34,  3.69s/it]10:28:30<37:21, 1120.93s/it]  \n",
      "253it [26:19,  6.24s/it]10:44:04<17:44, 1064.86s/it]\n",
      "100%|██████████| 20/20 [11:10:24<00:00, 2011.22s/it]\n"
     ]
    }
   ],
   "source": [
    "model = train(train_dataloader, vocab_size, epochs=20, lr=0.005, log=True, verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"./checkpoints/HLAN_LE_20epochs.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's evaluate the model. Here we need to use sigmoid activation because it is multiclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = HierarchicalAttentionNetwork(vocab_size=vocab_size, embed_size=EMBED_SIZE, hidden_size=HIDDEN_SIZE, num_sentences=NUM_SENTENCES, sentence_length=SENTENCE_LENGTH, num_classes=NUM_CLASSES)\n",
    "model.load_state_dict(torch.load(\"./checkpoints/HLAN_LE_20epochs.pt\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/50 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50/50 [00:55<00:00,  1.11s/it]\n"
     ]
    }
   ],
   "source": [
    "all_logits = []\n",
    "all_probs = []\n",
    "all_labels = []\n",
    "all_labels_actuals = []\n",
    "with torch.no_grad():\n",
    "    for x, y in tqdm(valid_dataloader):\n",
    "        logits = model(x)\n",
    "        probs = F.sigmoid(logits)\n",
    "        labels = torch.where(probs > 0.5, torch.ones(probs.shape), torch.zeros(probs.shape))\n",
    "\n",
    "        all_logits.append(list(logits.numpy()))\n",
    "        all_probs.append(list(probs.numpy()))\n",
    "        all_labels.append(list(labels.numpy()))\n",
    "        all_labels_actuals.append(list(y.numpy()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshold: 0.1\n",
      "Accuracy: 0.18715774843641417\n",
      "Precision: 0.20143605086013464\n",
      "Recall: 0.725304319724227\n",
      "F1: 0.3153039243233118\n",
      "\n",
      "Threshold: 0.2\n",
      "Accuracy: 0.22248635798800584\n",
      "Precision: 0.30860311750599523\n",
      "Recall: 0.44360659269632663\n",
      "F1: 0.3639899235426703\n",
      "\n",
      "Threshold: 0.3\n",
      "Accuracy: 0.21055350553505536\n",
      "Precision: 0.4007022471910112\n",
      "Recall: 0.3073359905203059\n",
      "F1: 0.34786319575687374\n",
      "\n",
      "Threshold: 0.4\n",
      "Accuracy: 0.16571075619871173\n",
      "Precision: 0.47810590631364563\n",
      "Recall: 0.20230528923839275\n",
      "F1: 0.284308530769813\n",
      "\n",
      "Threshold: 0.5\n",
      "Accuracy: 0.11634076839933183\n",
      "Precision: 0.5697786333012512\n",
      "Recall: 0.12754497468490789\n",
      "F1: 0.20843235630666315\n",
      "\n"
     ]
    }
   ],
   "source": [
    "thresholds = [0.1, 0.2, 0.3, 0.4, 0.5]\n",
    "for threshold in thresholds:\n",
    "    preds = np.concatenate(all_probs)\n",
    "    actuals = np.concatenate(all_labels_actuals)\n",
    "    preds = np.where(preds > threshold, 1, 0)\n",
    "    acc, prec, rec, f1 = all_micro(preds.ravel(), actuals.ravel())\n",
    "    print(f\"Threshold: {threshold}\")\n",
    "    print(f\"Accuracy: {acc}\")\n",
    "    print(f\"Precision: {prec}\")\n",
    "    print(f\"Recall: {rec}\")\n",
    "    print(f\"F1: {f1}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the paper reached 64% F1 after 100 epochs. Ours reached 36% F1 after 30 epochs. Would 70 more epoch help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bd4h",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
